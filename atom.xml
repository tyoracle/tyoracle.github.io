<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>IT 职业生涯规划</title>
  <subtitle>时间的朋友</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://username.github.io/"/>
  <updated>2017-02-10T13:16:50.774Z</updated>
  <id>http://username.github.io/</id>
  
  <author>
    <name>TY</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>该奋斗了</title>
    <link href="http://username.github.io/2017/02/06/%E8%AF%A5%E5%A5%8B%E6%96%97%E4%BA%86/"/>
    <id>http://username.github.io/2017/02/06/该奋斗了/</id>
    <published>2017-02-05T16:00:00.000Z</published>
    <updated>2017-02-10T13:16:50.774Z</updated>
    
    <content type="html"><![CDATA[<h2 id="假期都做了什么"><a href="#假期都做了什么" class="headerlink" title="假期都做了什么"></a>假期都做了什么</h2><p>2017年的春节就这样过去了，转眼就到了年初十了，在过去的将近十天时间里，你过得如何呢？是陪伴着家人？还是被一大帮朋友拉着在外面胡吃海喝？还是以特别的方式渡过这个鸡年的春节？当大部分人都处于完全放松的状态时，却有一小部分人，永不知倦，继续着自己学习的轨迹，远远地把我们抛在了身后。</p>
<p>这就是选择什么样渡过假期的方式，就决定了你未来的生活质量了。</p>
<p>相信今天应该是很多人假期结束后回到公司上班的第一天，刚结束假期，是不是有点假期综合症？这个生物钟早已习惯了半夜才睡，中午才起的模式了。早上当闹钟响起来的时候，艰难地爬起床来，那真的是痛苦。因为人不是机器，想切换模式就切换模式。那我们如何能快速的进入到新的角色呢？</p>
<a id="more"></a>
<h2 id="建立新的生活习惯"><a href="#建立新的生活习惯" class="headerlink" title="建立新的生活习惯"></a>建立新的生活习惯</h2><p>在假期的时候，很多人，晚上都外了与朋友相聚，或是各类活动，搞到两三点都不睡是很正常的，因为第二天可以睡到日上三杆。但生活不可能一直这样“幸福”下去，我们必须要想起自己今年定下的目标，至少要想想，为着自己的生计，也得准时去上班吧。</p>
<p>所以，建立新的生活习惯的第一步，是设置闹钟，呵，我可不是让你设置让你准时起来的闹钟，因为那随时可能会被你在惺松中按掉而倒头继续睡。我说的是让你设置一个提醒你睡觉的闹钟，这样，就可以不必顾着玩电脑，刷微信的时候，忘了按时去睡觉，从而早上起不来。</p>
<p>古人的早睡早起是非常好的一个彦语，暂不从中医的角度去解释，至少可以让你有充足的时间去休息，然后慢慢的将生活习惯调整过来。</p>
<h2 id="目标在那"><a href="#目标在那" class="headerlink" title="目标在那"></a>目标在那</h2><p>2017年过去了一个多月了，猴年也过去了，请问身为IT人的你，2017年的目标在那呢？是不是过了一个年就忘得差不多了？还是需要重新确立新的目标？其实每天早上叫醒你的，并不是闹钟，而是心中那个目标。所以，请重新思考一下，1月份定的目标，自己完成了多少？还是只是一纸的空谈呢？</p>
<h2 id="职业发展"><a href="#职业发展" class="headerlink" title="职业发展"></a>职业发展</h2><p>每个人的成长都离不开职业发展，无论是从业者，还是自己创业，都需要认真考虑一下，自己未来的路该如何走，这个博客在过年的时候，重新做了新的定位，从以前单纯的ORACLE技术博客，转变为IT职业生涯的规划与技术的分享。因为我知道，有很多刚刚步入IT行业的小伙伴们，都是凭着兴趣，或是凭着谋生的需要而加入，但却不知自己最终想要的是些什么。包括以前的自己也是一样，十几年的IT从业时间，跌跌撞撞，才走到了今天。假如自己在开始的时候，就有了明确的职位生涯规划，可能会更容易走向成功。所以我希望将自己的技术与对职业生涯的感悟，放着这里与大家分享，共同进步。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;假期都做了什么&quot;&gt;&lt;a href=&quot;#假期都做了什么&quot; class=&quot;headerlink&quot; title=&quot;假期都做了什么&quot;&gt;&lt;/a&gt;假期都做了什么&lt;/h2&gt;&lt;p&gt;2017年的春节就这样过去了，转眼就到了年初十了，在过去的将近十天时间里，你过得如何呢？是陪伴着家人？还是被一大帮朋友拉着在外面胡吃海喝？还是以特别的方式渡过这个鸡年的春节？当大部分人都处于完全放松的状态时，却有一小部分人，永不知倦，继续着自己学习的轨迹，远远地把我们抛在了身后。&lt;/p&gt;
&lt;p&gt;这就是选择什么样渡过假期的方式，就决定了你未来的生活质量了。&lt;/p&gt;
&lt;p&gt;相信今天应该是很多人假期结束后回到公司上班的第一天，刚结束假期，是不是有点假期综合症？这个生物钟早已习惯了半夜才睡，中午才起的模式了。早上当闹钟响起来的时候，艰难地爬起床来，那真的是痛苦。因为人不是机器，想切换模式就切换模式。那我们如何能快速的进入到新的角色呢？&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>2017_new_begining</title>
    <link href="http://username.github.io/2017/01/03/2017_new_begining/"/>
    <id>http://username.github.io/2017/01/03/2017_new_begining/</id>
    <published>2017-01-02T16:00:00.000Z</published>
    <updated>2017-02-03T09:31:16.410Z</updated>
    
    <content type="html"><![CDATA[<h2 id="感想"><a href="#感想" class="headerlink" title="感想"></a>感想</h2><p>当时光飞逝，进入2017年已经三天了，感觉还是停留在2016里，恍如昨日。时间总是在过去了，才会让人感觉到飞快，拥有的时候，才不知如何使用，白白浪费在刷微信，浏览无聊的网页上。</p>
<p>在朋友圈，这几天不断的刷着2016的成绩与2017的计划，这种期望是好的，但是又有多少人在年底的时候能完成自己年初定下的计划，并且完成的呢？</p>
<p>在新一年的开始，的确需要对过去进行回顾，对未来进行规划，但是任何的一切，不会因为新的一年而改变，如未读的书依然在书柜里，未背的单词，还是不会，未跑的里程，还是需要用汗水去浇灌。如果你今年还是定下了要读多少本书，背多少单词，做多少事，只不过是把往年的计划重复。对你来说，2017并没有什么特别。</p>
<p>我们是需要将每一年活出精彩，还是重复过着每一年的生活呢？这需要我们每个人深入地思考。</p>
<p>在新年伊始，回顾与展望，的确让人有一种庄严的仪式感。这样可以让人有一种新生的感觉。那我也不能免俗，让自己在2017年写下新一年的初步计划。</p>
<p>2016年里发生了很多的事情，世界的，中国的，身边的，但那是外部的环境，你不能改变，那只能适应。2016年是一个知识变现的年，在这一年里，看到很多技术牛人，将知识通过网络变现，知识开始以各种不同的付费形式出现。而我也参与其中，成为付费学习的一份子。在2017，需要将这些付费学习的知识，整理成文字，内化在自己的思维里，才不枉付出时间与金钱进行学习。</p>
<p>财富自由，生涯规划，人生升级，这些概念，需要无时无刻的提醒自己去不断地思考，反省与努力。</p>
<p>2017年，需要更关注时间的消耗，时间是不可再生资源，你的时间花在了这些地方，就没有时间进行学习。时间放在那，成长就在那。希望是一个人前进的动力，虽然前路并不可知，但是认准了方向，只需去做就行了，做了，至少你往前移动了一点，能看清前方的路也多一点，所以怀着希望，认准方向，就拼命去努力，不要浪费时间在那里胡思乱想。</p>
<p>再多的计划都是空谈，实干出真知，简单地说，继续一百天的计划，一百天跑步，一百篇博客更新，一百天持续英语朗读，每天坚持碎片化学习付费订阅，学习冥想。</p>
<p>其实最好的执行方式，取于一张A4纸自制一个2017的日历，每坚持一天，就在上面打个圆圈，对，这是我准备去做的。</p>
<p>愿你我在2017年活出与2016年不一样的自我，而不是重复过去一年的自己。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;感想&quot;&gt;&lt;a href=&quot;#感想&quot; class=&quot;headerlink&quot; title=&quot;感想&quot;&gt;&lt;/a&gt;感想&lt;/h2&gt;&lt;p&gt;当时光飞逝，进入2017年已经三天了，感觉还是停留在2016里，恍如昨日。时间总是在过去了，才会让人感觉到飞快，拥有的时候，才不知如何使用，
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>JDBC参数导致大量的library cache lock</title>
    <link href="http://username.github.io/2016/09/30/JDBC%E5%8F%82%E6%95%B0%E5%AF%BC%E8%87%B4%E5%A4%A7%E9%87%8F%E7%9A%84library%20cache%20lock/"/>
    <id>http://username.github.io/2016/09/30/JDBC参数导致大量的library cache lock/</id>
    <published>2016-09-29T16:00:00.000Z</published>
    <updated>2017-02-03T10:05:37.693Z</updated>
    
    <content type="html"><![CDATA[<h2 id="个人介绍"><a href="#个人介绍" class="headerlink" title="个人介绍"></a>个人介绍</h2><p>本人TY，从事ORACLE DBA十五年，从ORACLE 8I开始，一直奋战在一线，本着对技术的狂热，一直走到今天，积累了大量的经验与案例，期待静下心来，将这些案例与经验化成文字，与大家分享，共同进步。</p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>今天要与大家分享的是一个关于JDBC参数设置引起数据库BUG的故事，也许大家会不以为然，BUG多么的简单，直接到metalink上去查不就可以了吗？但是解决问题的时候，你不知道是bug，我们只能从故障表现出来的种种蜘丝马迹去推断，把问题从未知向已知一步步推进。这才是故障解决的关键，我们要学习的是解决故障的思路，当你清晰了整个故障的前因后果，你会发现，寻寻觅觅，原来就是这么简单，但是正因为有了从未知到已知这个推断过程，才有了解决问题后那种乐趣，才体现了对困难的挑难，对能力的提升。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a><strong>背景</strong></h2><p>故事的背景也如大多的故事一样，客户刚从11.1.0.7升级到11.2.0.3，升级后经常遇到’library cache lock’ 和’library cache: mutex X’ 等待事件，一个本来CPU平时占用不到10%的清闲系统，经常CPU占用百分百，严重影响了业务的正常运行。关于这个library cache，因为其结构复杂，并且在数据库结构中非常重要，所以出现问题的概率非常高，其实可以写一系列的文章，大家以后可以继续关注。</p>
<p>既然出现问题了，作为服务商，当然第一时间赶赴现场进行分析，因为出现library cache的问题，往往会占用大量的db time，从而影响到业务的正常运行，必须第一时间去解决问题，否则对客户的影响会越来越大。<br><a id="more"></a><br>分析问题的第一步，当然是提取问题时间段的AWR进行检查<br><img src="http://odh3pyi7v.bkt.clouddn.com/lb_awr_1.jpg" alt=""></p>
<p>从上面可以看到，系统的大部分资源被library cache 这两个相关的等待事件所占。<br><img src="http://odh3pyi7v.bkt.clouddn.com/lb_awr_2.jpg" alt=""></p>
<p>系统中伴有大量的解析失败，<br><img src="http://odh3pyi7v.bkt.clouddn.com/lb_awr_3.jpg" alt=""></p>
<p>每秒中的解析分析次数甚至达到了18次。我们知道Library cache handle是对象的一个指针，<br>其中的namespace属性表示其指向的对象的类型：比如CRSR(Cursor)，TABL(Table)，INDX(Index) ，PROD(Procedure)，TRIG(Trigger)等等。<br>当一条SQL需要进行解析时，其分为硬解析与软解析两种，在进行了语法分析，权限与对象检查后，如果是<br> Hard Parse： 是指在library cache 中经过hash function找不到对应指针的时候，他就要进行申请内存，获得handle上的library cache 上的锁，并且把<br> sql相关的对象及统计信息加载到内存，选择执行计划，产生执行计划<br>  如果这条SQL已经在library cache里,则通过hash function定位到handle指针的入口，根据运行的环境与变量，选择执行计划，产生执行计划，这个叫作软解析。<br>在上面的AWR里看到，大量的硬解析与解析失败，这些都是与library cache lock相关的，所以library cache lock占了系统资源80%。</p>
<p>既然从AWR里看到，是因为失败解析过多导致了故障，那是不是就可以跟客户说，你去检查应用是不是有改变，然后你拍拍屁股就可以走人呢？这绝对不是，今时今日这样的服务态度是不行的，我们必须提供精准的根因分析，告诉客户根因并帮客户解决才是我们的服务忠旨。</p>
<p>但是从AWR里想找到问题的根源是很难的，我们只能通过数据库的trace进行问题的定位，看看为什么会产生这么多失败解析。获取数据库trace，无非就是三板斧：<br>10046<br>Hanganayale<br>Systemstate dump<br>在这里，在问题重现时，我们执行了hanganalyze 3和Systemstate level 10的dump。产生了下面的trace</p>
<pre><code> 
HANG ANALYSIS:
 instances (db_name.oracle_sid): chfdb101_dg.chfdb101_dg
 oradebug_node_dump_level: 3
 analysis initiated by oradebug
 os thread scheduling delay history: (sampling every 1.000000 secs)
 0.000000 secs at [ 00:05:03 ]
 NOTE: scheduling delay has not been sampled for 1.004909 secs 0.000000 secs from [ 00:05:00 - 00:05:04 ], 5 sec avg
 0.000000 secs from [ 00:04:05 - 00:05:04 ], 1 min avg
 0.000000 secs from [ 00:00:05 - 00:05:04 ], 5 min avg
===============================================================================

Chains most likely to have caused the hang: <<< === !!!!!!!!!!!! === <<<
 [a] Chain 1 Signature: 'library cache: mutex X'<='library 1="" 2="" 3="" cache="" lock'<="library cache lock" chain="" signature="" hash:="" 0x88fb478b="" [b]="" signature:="" 'library="" cache:="" mutex="" x'<="library cache lock" <="library cache lock" [c]="" ##################################################################################################################################=""> Oracle session identified by:
 {
 instance: 1 (chfdb101_dg.chfdb101_dg)
 os id: 11613
 process id: 116, oracle@chfsdallindb142
 session id: 352
 session serial #: 5
 }
 which is waiting for 'library cache: mutex X' with wait info:
 {
 p1: 'idn'=0xb9b5d3a9
 p2: 'value'=0x30c00000000
 p3: 'where'=0x52
 time in wait: 0.050099 sec
 timeout after: never
 wait id: 6503935
<font color="red">
 blocking: 98 sessions <<<< === !!!!!!!!!!!!!!! $$$$$$$$$$$$$$$$$$$$$ !!!!!!!!!!!!!! === <<<
 current sql: select rowid, * FROM FEE_COUNTER WHERE ACCOUNT_ID = :1 AND FEE_COUNTER_RULE_ID = :2 ORDER BY EXPIRE_DATETIME ASC 
</font>
 short stack: ksedsts()+461<-ksdxfstk()+32<-ksdxcb()+1876<-sspuser()+112<-__sighandler()<-semtimedop()+10<-skgpwwait()+160<-ksliwat()+1865<-kslwaitctx()+163<-ksfwaitctx()+14<-kgllockwait()+867<-kglupgradelock()+1168<-kksgetbuildlock()+321<-kksfbc()+12362<-kkspsc0()+1173<-kksparsecursor()+116<-opiosq0()+1965<-kpooprx()+ <="" code=""></-ksdxfstk()+32<-ksdxcb()+1876<-sspuser()+112<-__sighandler()<-semtimedop()+10<-skgpwwait()+160<-ksliwat()+1865<-kslwaitctx()+163<-ksfwaitctx()+14<-kgllockwait()+867<-kglupgradelock()+1168<-kksgetbuildlock()+321<-kksfbc()+12362<-kkspsc0()+1173<-kksparsecursor()+116<-opiosq0()+1965<-kpooprx()+></='library></code></pre>

<p>从trace里看到，一条简单的select语句，阻塞了98个会话。这个时候，有经验的DBA会根据call stack到metalink上去找，看看是不是遇到什么bug。那好吧，我们也去看看，有没有与我们现象相吻合的<br>那我们修改mysqld_safe的脚本,限制其加载的目录，修改这一段为</p>
<pre><code> 
Bug Relevancy: 34%    16620646    32    MANY SESSIONS WAITING ON LIBRARY CACHE LOCK DUE TO "BUILD".XXX LOCK
library cache: mutex X 10,035,748 ... wait event kslwaitctx ksfwaitctx kglLockWait kglUpgradeLock kksGetBuildLock kksfbc KKS: Find Bound Cursor kkspsc0 kksParseCursor    14-Apr-2013    Q5    G226    RDBMS-112035    V112035

BUG    Relevancy: 34%    16870682    36    ESSC: LIBRARY CACHE LOCK 60%, MUTEX X 20%, CONCURRENT DDL, DML, Q ON PT
11.2.0.3.3 LIB CACHE PRODID-5 PORTID-226 12633340 Abstract: ESSC: LIBRARY CACHE LOCK 60%, MUTEX X 20%, CONCURRENT    19-Jun-2013    Q5 G226    RDBMS-112033    V112033
Base Bug    12633340 <<<< === best match !!!!

BUG    Relevancy: 33%    15949056    33    HIGH LIBRARY CACHE LOCK WAIT EVENTS
library cache: mutex X . Top 5 Timed ... )+2704<-kksgetbuildlock 11="" 27="" 14380605="" ()+720<-kksfbc()+23360<-kkspsc0()+3296<-kksparsecursor()+256<-opiosq0()+4160<-="" kpooprx()+432<-kpoal8="" 15-mar-2013="" q5="" g197="" rdbms-112034="" v112034="" bug="" relevancy:="" 33%="" high="" library="" cache="" lock,cursor:="" pin="" s="" wait="" on="" x="" and="" cache:="" mutex="" abstract:="" ***="" gramacha="" 07="" ...="" concurrency="" 11,715,680="" 28-jan-2013="" g23="" rdbms-112032="" v112032="" <="" code=""></-kksgetbuildlock></code></pre>
上述几个bug都是三成左右的匹配，没有完全匹配的，为什么说不是完全匹配呢，因为上述那些bug都没有解析失败超高的现象，所以并不敢肯定就是遇到这些bug，只能继续研究下去。既然是怀疑解析失败导致了这个故障，那就需要定位是什么原因导致了cursor的解析失败，在这里，有一个cusror相关的event可以帮助我们定位问题
<pre><code> 
ALTER SYSTEM SET EVENTS '10035 trace name context forever, level 10';
<monitor your="" alert.log="">
ALTER SYSTEM SET EVENTS '10035 trace name context off';
</monitor></code></pre>
设置了上述的event后，只要出现解析失败，就会在alert.log里打出相应的信息
<pre><code> 
select rowid, * FROM FEE_COUNTER WHERE ACCOUNT_ID = :1 AND FEE_COUNTER_RULE_ID = :2 ORDER BY EXPIRE_DATETIME ASC
PARSE ERROR: ospid=2485, error=936 for statement:
……
select rowid, DISTINCT PA.PROGRAM_ID FROM CARDHOLDER CH, PROGRAM_ACCESS PA WHERE CH.CARDHOLDER_ID = PA.CARDHOLDER_ID AND CH.CARDHOLDER_STATUS_ID = 1 AND PA.ACCESS_STATUS_ID = 1 AND CH.CARD_ID = :1 AND CH.PERSON_ID = :2
</code></pre>

<p>可以看到，打出来的SQL，感觉很奇怪，原来是到了11g版本后，语法校验严格了，而以前的版本，因为语法检查没有那么严格，所以没有报错，我们可以手工重现这个解析失败的错误</p>
<p><pre><code><br>select rowid, * FROM FEE_COUNTER WHERE ACCOUNT_ID = :1 AND FEE_COUNTER_RULE_ID = :2 ORDER BY EXPIRE_DATETIME ASC</code></pre></p>
<p>ERROR at line 1:<br>ORA-00936: missing expression</p>
<p>如果加上<br>select rowid, FEE_COUNTER.* FROM FEE_COUNTER WHERE ACCOUNT_ID = :1 AND FEE_COUNTER_RULE_ID = :2 ORDER BY EXPIRE_DATETIME ASC<br>则不会报错。<br><br>将上述的发现与客户沟通后，客户说，我们没有这样的写法，我们的写法都是</p>
<p><pre><code><br>select * FROM FEE_COUNTER WHERE ACCOUNT_ID = :1 AND FEE_COUNTER_RULE_ID = :2 ORDER BY EXPIRE_DATETIME ASC<br></code></pre><br>都不会加rowid的，那真神奇了，这个rowid从那里来的呢？怀疑来怀疑去，数据库层面不会改写SQL加入rowid的，那只能去看看代码上有什么特别的地方。</p>
<p>看了一下客户的代码，发现了一个比较特别的地方<br><img src="http://odh3pyi7v.bkt.clouddn.com/lb_awr_4.jpg" alt=""> </p>
<p>对于这个ResultSet.TYPE_SCROLL_SENSITIVE，感觉会不会是个坑呢？到网上搜过了一把关于他的资料。<br>“对于TYPE_SCROLL_INSENSITIVE,一次查询的结果可能存在数据库端的内存缓冲中，也可以直接发送到JVM的内存中，<br>如果结果集很小，会直接发送到JVM层，然后被next定位，转换数据类型，显示，或者缓存在数据库内存中。总之<br>查询结果已经和数据库脱离，这时如果数据库记录被其它进程更新，则结果集无法得知，还是使用缓存的记录。<br>而对于TYPE_SCROLL_SENSITIVE，一次查询的结果并不是直接的记录被缓存下来，只是符合条件的记录的“原始ROWID”<br>被缓存了，然后next定位到这条记录时，<br>数据库会再次根据这个ROWID做底层操作：<br>select * from axmantest where rowid = rd_file_offset_0x111010101001;”</p>
<p>原来就是这个参数导致了每条SQL都自动增加了rowid，对于select * 和select distinct（聚合函数不会有rowid）的操作都会报解析失败。</p>
<p>我们尝试使用以下的java代码去验证，是不是真的就是ResultSet.TYPE_SCROLL_SENSITIVE这个JDBC参数导致了问题的出现</p>
<p><pre><code><br>package com.oracle.test;</code></pre></p>
<p>import java.sql.Connection;<br>import java.sql.DatabaseMetaData;<br>import java.sql.DriverManager;<br>import java.sql.ResultSet;<br>import java.sql.SQLException;<br>import java.sql.Statement;<br>import java.util.Locale;</p>
<p>import oracle.jdbc.rowset.OracleJDBCRowSet;</p>
<p>/*</p>
<p>CREATE TABLE customers<br>(<br> id NUMBER,<br> credit_limit NUMBER,<br> email VARCHAR2(30)<br>);</p>
<p>INSERT INTO customers VALUES (1, 1000, ‘sean.li@oracle.com’);<br>select id, credit_limit from customers where id = 1; </p>
<p>*/</p>
<p>public class ScrollableResultSet {</p>
<p> /**</p>
<ul>
<li><p>@param args<br>*/<br>public static void main(String[] args) throws Exception{<br>useConnection();<br>}</p>
<p>public static void useConnection() throws Exception {<br>Class.forName(“oracle.jdbc.OracleDriver”);<br>Connection connection = DriverManager.getConnection(“jdbc:oracle:thin:@localhost:1521:orcl”, “sean”, “welcome1”);<br>printConnectionMetaData(connection);<br>printEnvironmentInfo();<br>Statement statement = connection.createStatement(ResultSet.TYPE_SCROLL_INSENSITIVE,ResultSet.CONCUR_READ_ONLY);<br>ResultSet resultSet = statement.executeQuery(“select * from customers”);<br>if (resultSet.next()){<br>System.out.println(resultSet.getString(1));<br>}<br>connection.close();<br>}</p>
<p>public static void useRowSet() throws SQLException {<br>OracleJDBCRowSet rowset = new OracleJDBCRowSet();<br>try {<br>rowset.setUsername(“sean”);<br>rowset.setPassword(“welcome1”);<br>rowset.setUrl(“jdbc:oracle:thin:@localhost:1521:orcl”);<br>rowset.setType(ResultSet.TYPE_SCROLL_SENSITIVE);<br>rowset.setCommand(“select * from customers”);<br>rowset.execute();<br>if (rowset.next()){<br>System.out.println(rowset.getString(1));<br>}<br>} finally {<br>rowset.close();<br>}<br>}</p>
<p>public static void printEnvironmentInfo() {<br>// Get JVM information.<br>java.util.Properties props = System.getProperties();<br>System.out.println(“\nJVM\n===”);<br>System.out.println(props.getProperty(“java.vm.vendor”));<br>System.out.println(props.getProperty(“java.vm.name”));<br>System.out.println(props.getProperty(“java.vm.version”));<br>System.out.println(props.getProperty(“java.version”));</p>
<p>// Get environment information.<br>System.out.println(“\nLOCALE\n===========”);<br>System.out.println(Locale.getDefault());</p>
<p>// Get CLASSPATH<br>String pathseparator = props.getProperty(“path.separator”);<br>String classpath = props.getProperty(“java.class.path”);<br>System.out.println(“\nCLASSPATH\n=========”);<br>String[] strarr = classpath.split(pathseparator);<br>for (int i = 0; i &lt; strarr.length; i++)<br>System.out.println(strarr[i]);</p>
<p>// Get LIBRARY PATH<br>String libpath = props.getProperty(“java.library.path”);<br>System.out.println(“\nLIBRARYPATH\n===========”);<br>strarr = libpath.split(pathseparator);<br>for (int i = 0; i &lt; strarr.length; i++)<br>System.out.println(strarr[i]);<br>}</p>
<p>public static void printConnectionMetaData(Connection conn) throws SQLException {<br>DatabaseMetaData meta = conn.getMetaData();</p>
<p>// gets driver info:<br>System.out.println(“\nDatabase\n==============”);<br>System.out.println(meta.getDatabaseProductVersion());<br>System.out.println(“\nJDBC\n==============”);<br>System.out.println(meta.getDriverName() + “: “ + meta.getDriverVersion());<br>System.out.println(“\nConnection URL\n==============”);<br>System.out.println(meta.getURL());<br>}<br>}</p>
</li>
</ul>
<p><br>通过追踪发现，执行这个程序时，的确会执行<br>select rowid,<em> from customers<br>而我们在程序里写的SQL是select </em> from customers，JDBC这个参数自动地帮我们加上了rowid，而正是这个多此一举，导致了此次的故障。</p>
<p>根据ResultSet.TYPE_SCROLL_SENSITIVE 去metalink上查找，这时就能很快的定位到BUG:17040042 - ROWID ADDED BY JDBC DRIVER TO SUPPORT SCROLL SENSITIVE CAUSES PARSE FAILURES</p>
<p>知道了原因，解决也很简单了，将ResultSet.TYPE_SCROLL_SENSITIVE这个参数改为ResultSet.TYPE_SCROLL_INSENSITIVE。</p>
<h2 id="原因总结及建议"><a href="#原因总结及建议" class="headerlink" title="原因总结及建议"></a>原因总结及建议</h2><p>分析问题是一个抽丝剥茧的过程，当你在这个问题当中的时候，你可能会看不到什么清晰的方向，但只要仔细分析相关的线索，总会给你指出一个方向，然后跟着这个方向，一步一步的往前走，便会觉得豁然开朗。</p>
<p>其实这个问题，也引出了另一个问题，就是升级到11GR2后，数据库对SQL的语法检查变得严格了，所以这个问题在升级前没有出现，而升级到11GR2后，应用没有改变的前提下，这个问题暴露了出来。</p>
<p>例如，下面的这个例子中，a b c三张表都有id字段，但是在select部分中,id没有指定来自那张表，<br>但是在10g版本中，却没有报错，这本来就不正常。<br>到了11g版本后，语法校验更加严格了，结果报语法错误ORA-00918.<br>解决方法：修改应用程序，将id字段添加表的别名<br><img src="http://odh3pyi7v.bkt.clouddn.com/lb_awr_5.jpg" alt=""></p>
<p><img src="http://odh3pyi7v.bkt.clouddn.com/lb_awr_6.jpg" alt=""></p>
<p>所以各位在升级数据库前，一定要做足严格的测试，避免踩到坑里去：-）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;个人介绍&quot;&gt;&lt;a href=&quot;#个人介绍&quot; class=&quot;headerlink&quot; title=&quot;个人介绍&quot;&gt;&lt;/a&gt;个人介绍&lt;/h2&gt;&lt;p&gt;本人TY，从事ORACLE DBA十五年，从ORACLE 8I开始，一直奋战在一线，本着对技术的狂热，一直走到今天，积累了大量的经验与案例，期待静下心来，将这些案例与经验化成文字，与大家分享，共同进步。&lt;/p&gt;
&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;今天要与大家分享的是一个关于JDBC参数设置引起数据库BUG的故事，也许大家会不以为然，BUG多么的简单，直接到metalink上去查不就可以了吗？但是解决问题的时候，你不知道是bug，我们只能从故障表现出来的种种蜘丝马迹去推断，把问题从未知向已知一步步推进。这才是故障解决的关键，我们要学习的是解决故障的思路，当你清晰了整个故障的前因后果，你会发现，寻寻觅觅，原来就是这么简单，但是正因为有了从未知到已知这个推断过程，才有了解决问题后那种乐趣，才体现了对困难的挑难，对能力的提升。&lt;/p&gt;
&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;故事的背景也如大多的故事一样，客户刚从11.1.0.7升级到11.2.0.3，升级后经常遇到’library cache lock’ 和’library cache: mutex X’ 等待事件，一个本来CPU平时占用不到10%的清闲系统，经常CPU占用百分百，严重影响了业务的正常运行。关于这个library cache，因为其结构复杂，并且在数据库结构中非常重要，所以出现问题的概率非常高，其实可以写一系列的文章，大家以后可以继续关注。&lt;/p&gt;
&lt;p&gt;既然出现问题了，作为服务商，当然第一时间赶赴现场进行分析，因为出现library cache的问题，往往会占用大量的db time，从而影响到业务的正常运行，必须第一时间去解决问题，否则对客户的影响会越来越大。&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>mysql的CVE-2016-6662安全漏洞修复</title>
    <link href="http://username.github.io/2016/09/28/mysql%E7%9A%84CVE-2016-6662%E5%AE%89%E5%85%A8%E6%BC%8F%E6%B4%9E/"/>
    <id>http://username.github.io/2016/09/28/mysql的CVE-2016-6662安全漏洞/</id>
    <published>2016-09-27T16:00:00.000Z</published>
    <updated>2017-02-03T10:21:23.821Z</updated>
    
    <content type="html"><![CDATA[<h2 id="个人介绍"><a href="#个人介绍" class="headerlink" title="个人介绍"></a>个人介绍</h2><p>本人TY，从事ORACLE DBA十五年，从ORACLE 8I开始，一直奋战在一线，本着对技术的狂热，一直走到今天，积累了大量的经验与案例，期待静下心来，将这些案例与经验化成文字，与大家分享，共同进步。</p>
<h1 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h1><p>最近几天，在安全方面最热门的话题应该是一个独立的研究组织发现多处严重的Mysql漏洞，此次通报的是其中比较严重的一个漏洞CVE-2016-6662，它允许攻击者远程注入恶意设置到被攻击服务器的Mysql配置文件(my.cnf)中，导致更加严重的后果。</p>
<p>该漏洞影响所有默认配置的Mysql版本分支(5.7、5.6、5.5)，包括最新的版本，并可能被攻击者进行本地或者远程的利用。exp既可以通过网络连接或者利用类似phpmyadmin之类的web管理工具，以及SQL注入漏洞等。</p>
<p>SQL注入漏洞是在web应用中最常见的漏洞之一，在存在注入漏洞的情况下，攻击者可以配合CVE-2016-6662进行更加深入的入侵。如果被攻击服务器有运行受影响的mysql版本，攻击用该漏洞的EXP可以以root权限执行任意代码，从而完全控制被攻击服务器。</p>
<p>该漏洞需要认证访问MYSQL数据库（通过网络连接或者像phpMyAdmin的web接口），以及通过SQL注入利用。攻击者成功利用该漏洞可以以ROOT权限执行代码，完全控制服务器。</p>
<p>利用条件：首先你要有一个Mysql低权限用户，仅需有FIle权限（例如：虚拟主机通常会提供，因为需要导入导出文件），即可实现Root权限提升，进而控制服务器</p>
<a id="more"></a>
<h1 id="漏洞影响"><a href="#漏洞影响" class="headerlink" title="漏洞影响"></a>漏洞影响</h1><p>MySQL  &lt;= 5.7.15       远程代码执行/ 提权 (0day)</p>
<pre><code>5.6.33

5.5.52
</code></pre><p>Mysql分支的版本也受影响,包括：</p>
<p>MariaDB</p>
<p>PerconaDB </p>
<h1 id="漏洞介绍"><a href="#漏洞介绍" class="headerlink" title="漏洞介绍"></a>漏洞介绍</h1><p>这个漏洞影响(5.7, 5.6, 和 5.5版本)的所有Mysql默认配置，包括最新的版本，攻击者可以远程和本地利用该漏洞。该漏洞需要认证访问MYSQL数据库（通过网络连接或者像phpMyAdmin的web接口），以及通过SQL注入利用。攻击者成功利用该漏洞可以以ROOT权限执行代码，完全控制服务器。</p>
<h1 id="官方修复建议："><a href="#官方修复建议：" class="headerlink" title="官方修复建议："></a>官方修复建议：</h1><p>临时修复建议：不要给远程用户SUPER或者FILE权限 </p>
<p>官方已经发布补丁：</p>
<p>方便升级的用户尽快升级MySQL版本，升级后的MySQL将限制ld_preload仅仅能够从/usr/lib64,/usr/lib这种系统目录和MySQL安装目录载入 </p>
<p>补丁下载地址；</p>
<p>使用MySQL5.5版本的用户</p>
<p><a href="https://www.percona.com/downloads/Percona-Server-5.5/" target="_blank" rel="external">https://www.percona.com/downloads/Percona-Server-5.5/</a></p>
<p>使用MySQL 5.6版本的用户</p>
<p><a href="https://www.percona.com/downloads/Percona-Server-5.6/Percona-Server-5.6.32-78.0/" target="_blank" rel="external">https://www.percona.com/downloads/Percona-Server-5.6/Percona-Server-5.6.32-78.0/</a></p>
<p>使用MySQL5.7版本的用户</p>
<p><a href="https://www.percona.com/downloads/Percona-Server-5.7/Percona-Server-5.7.14-7/" target="_blank" rel="external">https://www.percona.com/downloads/Percona-Server-5.7/Percona-Server-5.7.14-7/</a></p>
<p>上述的地址，说的是补丁，但是实质是下载新的版本，让你做升级。安装都需要重启MYSQL服务。<br>不方便升级的用户可以通过本文中的方法进行修复。</p>
<p>数据库用户权限</p>
<p>不要给远程用户SUPER或者FILE权限，然而 CVE-2016-6663 提及到即使没有FILE权限，也可以利用（根据MySQL发行日志怀疑是和REPAIR TABLE使用临时文件有关）</p>
<p>配置文件权限</p>
<p>新建一个空的my.cnf和.my.cnf文件在datadir目录（通常是/var/lib/mysql目录，owner/group为root,权限为0600）</p>
<p>其他的位置/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf （可以通过mysqld –help –version来查看mysqld的版本信息）</p>
<p>确保配置文件中的!includedir定义中的目录mysql用户不可写</p>
<p>通过权限配置mysql用户不能够写配置文件</p>
<h1 id="如何修复"><a href="#如何修复" class="headerlink" title="如何修复"></a>如何修复</h1><p>关于mysql的CVE-2016-6662安全漏洞，官方提供的方案都是安装到最新的版本，他们会在最新的版本进行补丁的修复，但对于现有的版本，mysql和percona都没有现成的patch可以应用修复。</p>
<p>所以，对于现在的版本，只有两个选择，一个是升级到新的版本，一个是手工去修改mysql_safe这个文件，避免其在非规定的目录中加载共享库，使其有权限进行SQL注入。另外，还需要结合控制参数文件的权限，这样才能手工修复漏洞。</p>
<p>下面介绍手工修复5.6.28的mysql版本的过程：</p>
<pre><code> 
[/root]#ps -ef|grep mysql
root      1544     1  0 Apr22 ?        00:00:00 /bin/sh /usr/bin/mysqld_safe --datadir=/mysqldata/data/ --pid-file=/mysqldata/mysql.pid
mysql     2276  1544  0 Apr22 ?        02:21:50 /usr/sbin/mysqld --basedir=/usr --datadir=/mysqldata/data/ --plugin-dir=/usr/lib64/mysql/plugin --user=mysql --log-error=/mysqldata/logs/mysql-error.log --pid-file=/mysqldata/mysql.pid --socket=/var/lib/mysql/mysql.sock

[/root]#mysql --version
mysql  Ver 14.14 Distrib 5.6.28, for Linux (x86_64) using  EditLine wrapper
</code></pre>
可以看到，系统中的mysql是使用root调用的mysqld_safe.
mysqld_safe脚本可以在命令行中指定 --malloc-lib参数，与此同时，也可以将该参数的 取值直接写到配置文件中； 坏就坏在指定了malloc-lib参数时，mysqld_safe的处理方式上：
<pre><code> 
If malloc-lib is empty, do nothing and return
If malloc-lib is 'tcmalloc', look for tcmalloc shared library in /usr/lib
If malloc-lib is an absolute path, assume it is a malloc shared library
</code></pre>
攻击者如果具有FILE权限，先将自己的"恶意代码"编译完成以后，保存到被攻击的服务器 上；

攻击者具有FILE权限，可以在数据库配置文件中(my.cnf)写入下面的配置；

# 漏洞演示
在进行漏洞修复前，我们演示一下，这个漏洞如何进行SQL注入，修改配置文件的
<pre><code> 
root@debian:~/# ls -l /etc/my.cnf 
-rw-r--r-- 1 mysql mysql 72 Jul 28 17:20 /etc/my.cnf


mysql> set global general_log_file = '/etc/my.cnf';
mysql> set global general_log = on;
mysql> select '

     ; injected config entry

     [mysqld]
     malloc_lib=/tmp/mysql_exploit_lib.so

     [separator]

     ';
1 row in set (0.00 sec)
mysql> set global general_log = off;
</code></pre>

<p>这时，/etc/my.cnf会在最后追加以下的内容：</p>
<pre><code> 
/usr/sbin/mysqld, Version: 5.6.28-enterprise-commercial-advanced-log (MySQL Enterprise Server - Advanced Edition (Commercial)). started with:
Tcp port: 3306  Unix socket: /var/lib/mysql/mysql.sock
Time                 Id Command    Argument
160929 16:03:26    12 Query     select '

     ; injected config entry

     [mysqld]
     malloc_lib=/tmp/mysql_exploit_lib.so  ---恶意代码

     [separator]

     '
160929 16:03:34    12 Query     set global general_log = off
</code></pre>
从上面可以看到，这时my.cnf这个配置文件已经被修改了，在数据库重启时，就会被人刻意加载了一些恶意的共享库。

恶意代码做一些清理工作，然后正常启动数据库，此外，还会fork一个子进程，启动一 个reverse shell。完成以后，攻击者就能以root 用户登录了数据库所在的服务器，可 以为所欲为。

# 修复过程
## 
## 1、确保没有远程用户的权限设置
根据漏洞的描述，首先要确保数据库中没有远程用户拥有super 或者 file权限。通过以下命令进行检查
<pre><code> 
mysql> select host,user,Super_priv,File_priv from user;
+-----------+-------------+------------+-----------+
| host      | user        | Super_priv | File_priv |
+-----------+-------------+------------+-----------+
| localhost | root        | Y          | Y         |
| 127.0.0.1 | root        | Y          | Y         |
| ::1       | root        | Y          | Y         |
| %         | xxxxxplus   | N          | N         |
| %         | replication | N          | N         |
| localhost | xxx1use     | Y          | N         |
| 10.14%    | xxxxx006    | N          | N         |
| 10.14%    | xxuser      | N          | N         |
+-----------+-------------+------------+-----------+
8 rows in set (0.00 sec)
</code></pre>

<p>当前系统中是没有远程用户拥有super 或者 file权限的，如果有的话，就存在漏洞，让这些用户可以远程注入SQL，修改相关的配置文件，加载一些共享库。</p>
<p>另外需要考虑，是否有远程用户对user表有修改权限。</p>
<p>## </p>
<h2 id="2、手工修改mysqld-safe的脚本"><a href="#2、手工修改mysqld-safe的脚本" class="headerlink" title="2、手工修改mysqld_safe的脚本"></a>2、手工修改mysqld_safe的脚本</h2><p> 漏洞可以用来启动服务器之前将其预加载共享库。使用这个代码进行加载：</p>
<p> –malloc-lib=LIB           Preload shared library LIB if available</p>
<p> 这个可以在my.cnf里设置<br> in a ‘[mysqld]’ or ‘[mysqld_safe]’ section.</p>
<p> 如果攻击者设法注入到内其恶意库的配置路径，他们将能够预加载任意库，从而在MySQL服务重新启动<br> 以root权限执行任意代码。   </p>
<p>上面已经说了，如果在mysqld_safe里指定绝对路径，那共享库就只能加载绝对路径下的库，这样可以控制绝对路径的权限来实施保护mysqld_safe加载的共享库是安全的。</p>
<p>那我们修改mysqld_safe的脚本,限制其加载的目录，修改这一段为</p>
<pre><code> 
    353       if [ ! -r "$malloc_lib" ]; then
    354         log_error "--malloc-lib '$malloc_lib' can not be read and will not be used"
    355         exit 1
    356       fi
    357       ;;

变成下面这个：

    353       if [ ! -r "$malloc_lib" ]; then
    354           log_error "--malloc-lib can not be read and will not be used"
    355         exit 1
    356 
    357      # Restrict to a the list in $malloc_dirs above
    358      case "$(dirname "$malloc_lib")" in
    359        /usr/lib) ;;
    360        /usr/lib64) ;;
    361        /usr/lib/i386-linux-gnu) ;;
    362        /usr/lib/x86_64-linux-gnu) ;;
    363        *)
    364          log_error "--malloc-lib must be located in one of the directories: $malloc_dirs"
    365          exit 1
    366          ;;
</code></pre>

<p>这段代码修改后不需要重启mysql，其会在以后的重启中生效。</p>
<p>##</p>
<h2 id="3、控制文件权限"><a href="#3、控制文件权限" class="headerlink" title="3、控制文件权限"></a>3、控制文件权限</h2><p>该漏洞需要能够写一些MySQL配置文件。如果能防止这一点，你就是安全的。<br>确保<br>/etc/my.cnf的权限是root:root 并且权限是0600</p>
<p>另外<br>新建一个空的my.cnf和.my.cnf文件在datadir目录（通常是/var/lib/mysql目录，owner/group为root,权限为0600）</p>
<p>其他的位置/etc/my.cnf /etc/mysql/my.cnf /usr/etc/my.cnf ~/.my.cnf （可以通过mysqld –help –version来查看mysqld的版本信息）如果存在，就需要配置为root:root权限为0600。</p>
<p>如果这些文件目录不存在，那可以不考虑，如 /etc/mysql，/usr/etc等，这些目录不在的话，可以不考虑修改。</p>
<p>确保配置文件中的!includedir定义中的目录mysql用户不可写</p>
<p>##</p>
<h2 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h2><p>从上面的分析可以看到，这个漏洞主要是利用了mysql的权限做文章，只要做到以下两点：</p>
<font color="red"><br>规范数据库账户的权限，不给账户赋予过多的权限；<br><br>mysql用户没有对任何配置文件的写权限。<br></font>


<p>上述的三个步骤，就是按上述两点去做的，只要做到就可以防止这个安全漏洞影响到你的数据库系统。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;个人介绍&quot;&gt;&lt;a href=&quot;#个人介绍&quot; class=&quot;headerlink&quot; title=&quot;个人介绍&quot;&gt;&lt;/a&gt;个人介绍&lt;/h2&gt;&lt;p&gt;本人TY，从事ORACLE DBA十五年，从ORACLE 8I开始，一直奋战在一线，本着对技术的狂热，一直走到今天，积累了大量的经验与案例，期待静下心来，将这些案例与经验化成文字，与大家分享，共同进步。&lt;/p&gt;
&lt;h1 id=&quot;概要&quot;&gt;&lt;a href=&quot;#概要&quot; class=&quot;headerlink&quot; title=&quot;概要&quot;&gt;&lt;/a&gt;概要&lt;/h1&gt;&lt;p&gt;最近几天，在安全方面最热门的话题应该是一个独立的研究组织发现多处严重的Mysql漏洞，此次通报的是其中比较严重的一个漏洞CVE-2016-6662，它允许攻击者远程注入恶意设置到被攻击服务器的Mysql配置文件(my.cnf)中，导致更加严重的后果。&lt;/p&gt;
&lt;p&gt;该漏洞影响所有默认配置的Mysql版本分支(5.7、5.6、5.5)，包括最新的版本，并可能被攻击者进行本地或者远程的利用。exp既可以通过网络连接或者利用类似phpmyadmin之类的web管理工具，以及SQL注入漏洞等。&lt;/p&gt;
&lt;p&gt;SQL注入漏洞是在web应用中最常见的漏洞之一，在存在注入漏洞的情况下，攻击者可以配合CVE-2016-6662进行更加深入的入侵。如果被攻击服务器有运行受影响的mysql版本，攻击用该漏洞的EXP可以以root权限执行任意代码，从而完全控制被攻击服务器。&lt;/p&gt;
&lt;p&gt;该漏洞需要认证访问MYSQL数据库（通过网络连接或者像phpMyAdmin的web接口），以及通过SQL注入利用。攻击者成功利用该漏洞可以以ROOT权限执行代码，完全控制服务器。&lt;/p&gt;
&lt;p&gt;利用条件：首先你要有一个Mysql低权限用户，仅需有FIle权限（例如：虚拟主机通常会提供，因为需要导入导出文件），即可实现Root权限提升，进而控制服务器&lt;/p&gt;
    
    </summary>
    
    
      <category term="Mysql" scheme="http://username.github.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>运营商异常缓慢SQL优化</title>
    <link href="http://username.github.io/2016/08/30/%E8%BF%90%E8%90%A5%E5%95%86%E5%BC%82%E5%B8%B8%E7%BC%93%E6%85%A2%E7%9A%84SQL%E4%BC%98%E5%8C%96/"/>
    <id>http://username.github.io/2016/08/30/运营商异常缓慢的SQL优化/</id>
    <published>2016-08-29T16:00:00.000Z</published>
    <updated>2017-02-03T09:15:46.155Z</updated>
    
    <content type="html"><![CDATA[<h1 id="运营商异常缓慢SQL优化"><a href="#运营商异常缓慢SQL优化" class="headerlink" title="运营商异常缓慢SQL优化"></a>运营商异常缓慢SQL优化</h1><p>今天到一个运营商进行深度巡检时，发现一条SQL运行次数频繁，并且占用资源非常高，这条SQL是对两个千万级的大表进行关联，根据电话号码进行查询，原来的语句运行非常缓慢，常常半个小时都执行不完，真不知道业务是怎么忍受运行这么缓慢的SQL。</p>
<p>因为需要对客户信息进行保密，只能在自己电脑上模拟相应的数据与优化结果</p>
<p>先创建两个表，然后模拟表的数据，分别插入3千万与2千5百万<br><a id="more"></a></p>
<pre><code> 
DROP TABLE t1;
create table t1 as
select
to_char(trunc(dbms_random.value(10000000000, 20000000000 ))) phone_no,
trunc(dbms_random.value(0, 30 )) ext,
lpad(rownum,10) v1,
rpad('x',100) padding
from
all_objects
where rownum <= 30="" 30000000;="" drop="" table="" t2;="" create="" t2="" as="" select="" to_char(trunc(dbms_random.value(10000000,="" 20000000000="" )))="" phone_no,="" trunc(dbms_random.value(0,="" ))="" ext,="" lpad(rownum,10)="" v1,="" rpad('x',100)="" padding="" from="" all_objects="" where="" rownum="" <="25000000;" code=""></=></code></pre>

<p>其原来的运行的SQL类似如下，运行半小时都不会出来结果的</p>
<pre><code> 
SELECT phone_no,ext,v1,padding
FROM t1
WHERE SUBSTR(t1.phone_no,1,8) IN
(SELECT t2.phone_no FROM t2 WHERE LENGTH(t2.phone_no)=8)
OR 
SUBSTR(t1.phone_no,1,9) IN
(SELECT t2.phone_no FROM t2 WHERE LENGTH(t2.phone_no)=9)
OR
SUBSTR(t1.phone_no,1,10) IN
(SELECT t2.phone_no FROM t2 WHERE LENGTH(t2.phone_no)=10)
OR
SUBSTR(t1.phone_no,1,11) IN
(SELECT t2.phone_no FROM t2 WHERE LENGTH(t2.phone_no)=11);

执行计划如下：
Execution Plan
/----------------------------------------------------------
Plan hash value: 2055931425

/---------------------------------------------------------------------------
| Id  | Operation          | Name | Rows  | Bytes | Cost (%CPU)| Time     |
/---------------------------------------------------------------------------
|   0 | SELECT STATEMENT   |      |    32 |  3168 |   159K  (1)| 00:31:54 |
|*  1 |  FILTER            |      |       |       |            |          |
|   2 |   TABLE ACCESS FULL| T1   | 66720 |  6450K|   379   (1)| 00:00:05 |
|*  3 |   TABLE ACCESS FULL| T2   |     5 |   110 |    76   (0)| 00:00:01 |
|*  4 |   TABLE ACCESS FULL| T2   |    31 |   682 |    25   (0)| 00:00:01 |
|*  5 |   TABLE ACCESS FULL| T2   |   389 |  8558 |     4   (0)| 00:00:01 |
|*  6 |   TABLE ACCESS FULL| T2   |   422 |  9284 |     3   (0)| 00:00:01 |
/---------------------------------------------------------------------------

Predicate Information (identified by operation id):
/---------------------------------------------------

   1 - filter( EXISTS (SELECT 0 FROM "T2" "T2" WHERE
              LENGTH("T2"."PHONE_NO")=8 AND "T2"."PHONE_NO"=SUBSTR(:B1,1,8)) OR
              EXISTS (SELECT 0 FROM "T2" "T2" WHERE LENGTH("T2"."PHONE_NO")=9 AND
              "T2"."PHONE_NO"=SUBSTR(:B2,1,9)) OR  EXISTS (SELECT 0 FROM "T2" "T2"
              WHERE LENGTH("T2"."PHONE_NO")=10 AND "T2"."PHONE_NO"=SUBSTR(:B3,1,10))
              OR  EXISTS (SELECT 0 FROM "T2" "T2" WHERE LENGTH("T2"."PHONE_NO")=11
              AND "T2"."PHONE_NO"=SUBSTR(:B4,1,11)))
   3 - filter(LENGTH("T2"."PHONE_NO")=8 AND
              "T2"."PHONE_NO"=SUBSTR(:B1,1,8))
   4 - filter(LENGTH("T2"."PHONE_NO")=9 AND
              "T2"."PHONE_NO"=SUBSTR(:B1,1,9))
   5 - filter(LENGTH("T2"."PHONE_NO")=10 AND
              "T2"."PHONE_NO"=SUBSTR(:B1,1,10))
   6 - filter(LENGTH("T2"."PHONE_NO")=11 AND
              "T2"."PHONE_NO"=SUBSTR(:B1,1,11))

Note
/-----
  - dynamic sampling used for this statement (level=2)
</code></pre>


<p>从上面的执行计划里比较容易看到两个问题：<br>1、两个大表，全表扫描，特别是T2全表扫了4次，并且使用filter,这个filter可以看成是NL连接的变种，你想想，几千万的表，做NL的连接，还要做几次，想想不慢也难啊<br>2、当前的执行计划使用了level 2的dynamic sampling，即代表当前表上没有统计信息或统计信息过旧，但是这个不是这条SQL运行缓慢的关键，因为重新收集了统计信息后，执行计划一样，运行时间一样。最重要的还是执行计划不好导致的。</p>
<p>既然知道了执行计划有问题，那我们就想办法优化吧，最简单的就是给T2的phone_no加上索引，效果立马显现。</p>
<pre><code> 
17:48:32 SQL> create index idx_t2_phoneno on t2(phone_no) ;

Index created.

18:18:48 SQL> exec DBMS_STATS.GATHER_TABLE_STATS (ownname => 'SYS' , tabname => 'T1',cascade => true, estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,method_opt=>'for all indexed columns size 1', granularity => 'ALL', degree => 1);

PL/SQL procedure successfully completed.

Elapsed: 00:00:00.79
18:20:50 SQL> exec DBMS_STATS.GATHER_TABLE_STATS (ownname => 'SYS' , tabname => 'T2',cascade => true, estimate_percent => DBMS_STATS.AUTO_SAMPLE_SIZE,method_opt=>'for all indexed columns size 1', granularity => 'ALL', degree => 1);

PL/SQL procedure successfully completed.

Elapsed: 00:00:00.56
</code></pre>

<p>重新运行SQL，加了索引后只需要2S左右就可以出来了结果了</p>
<pre><code> 
**Elapsed: 00:00:02.08**

Execution Plan
/----------------------------------------------------------
Plan hash value: 1293345318

/-------------------------------------------------------------------------------------
| Id  | Operation          | Name           | Rows  | Bytes | Cost (%CPU)| Time     |
/-------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT   |                |    32 |  3168 |  2035   (1)| 00:00:25 |
|*  1 |  FILTER            |                |       |       |            |          |
|   2 |   TABLE ACCESS FULL| T1             | 55915 |  5405K|   286   (2)| 00:00:04 |
|*  3 |   INDEX RANGE SCAN | IDX_T2_PHONENO |     1 |    12 |     1   (0)| 00:00:01 |
|*  4 |   INDEX RANGE SCAN | IDX_T2_PHONENO |     1 |    12 |     1   (0)| 00:00:01 |
|*  5 |   INDEX RANGE SCAN | IDX_T2_PHONENO |     1 |    12 |     1   (0)| 00:00:01 |
|*  6 |   INDEX RANGE SCAN | IDX_T2_PHONENO |     1 |    12 |     1   (0)| 00:00:01 |
/-------------------------------------------------------------------------------------

Predicate Information (identified by operation id):
/---------------------------------------------------

   1 - filter( EXISTS (SELECT 0 FROM "T2" "T2" WHERE
              "T2"."PHONE_NO"=SUBSTR(:B1,1,8) AND LENGTH("T2"."PHONE_NO")=8) OR  EXISTS
              (SELECT 0 FROM "T2" "T2" WHERE "T2"."PHONE_NO"=SUBSTR(:B2,1,9) AND
              LENGTH("T2"."PHONE_NO")=9) OR  EXISTS (SELECT 0 FROM "T2" "T2" WHERE
              "T2"."PHONE_NO"=SUBSTR(:B3,1,10) AND LENGTH("T2"."PHONE_NO")=10) OR  EXISTS
              (SELECT 0 FROM "T2" "T2" WHERE "T2"."PHONE_NO"=SUBSTR(:B4,1,11) AND
              LENGTH("T2"."PHONE_NO")=11))
   3 - access("T2"."PHONE_NO"=SUBSTR(:B1,1,8))
       filter(LENGTH("T2"."PHONE_NO")=8)
   4 - access("T2"."PHONE_NO"=SUBSTR(:B1,1,9))
       filter(LENGTH("T2"."PHONE_NO")=9)
   5 - access("T2"."PHONE_NO"=SUBSTR(:B1,1,10))
       filter(LENGTH("T2"."PHONE_NO")=10)
   6 - access("T2"."PHONE_NO"=SUBSTR(:B1,1,11))
       filter(LENGTH("T2"."PHONE_NO")=11)


Statistics
/----------------------------------------------------------
          0  recursive calls
          0  db block gets
     448827  consistent gets  <<---但是消耗的逻辑读还是非常大 0="" 1="" 508="" 534="" physical="" reads="" redo="" size="" bytes="" sent="" via="" sql*net="" to="" client="" received="" from="" roundtrips="" sorts="" (memory)="" (disk)="" rows="" processed="" <="" code=""></---但是消耗的逻辑读还是非常大></code></pre>

<p>优化到这里，是不是就可以实现优化的目标了呢？对于大部分人来说，从跑半小时都出不来结果，到现在2S左右就能出结果，这是一个非常大的优化，但是对于TY来说，这样的SQL还有优化的空间，因为消耗的逻辑读还是非常大。做事要不不做，要做就要做极致，这是我一直信奉的原则。既然这样，那我们继续看看还有没有优化的空间吧。</p>
<p>从上面看，虽然加了索引，但是filter这个条件还是在，我们要想办法将这个filter去掉才能实现最佳的优化效果。<br>1）通过分析，发现当前语句存在多个or，导致了无法走hash join只能走filter表连接方式的问题，复杂的or条件无法做or expansion.那我们试试人工将OR拆开，将语句改写如下：</p>
<pre><code> 
SELECT  phone_no,ext,v1,padding
FROM t1
WHERE SUBSTR(t1.phone_no,1,8) IN
(SELECT t2.phone_no FROM t2 WHERE LENGTH(t2.phone_no)=8)
union all 
SELECT  phone_no,ext,v1,padding
FROM t1 where
SUBSTR(t1.phone_no,1,9) IN 
(SELECT t2.phone_no FROM t2 WHERE LENGTH(t2.phone_no)=9)
union all 
SELECT  phone_no,ext,v1,padding
FROM t1 where
SUBSTR(t1.phone_no,1,10) IN
(SELECT t2.phone_no FROM t2 WHERE LENGTH(t2.phone_no)=10)
union all 
SELECT phone_no,ext,v1,padding
FROM t1 where
SUBSTR(t1.phone_no,1,11) IN
(SELECT t2.phone_no FROM t2 WHERE LENGTH(t2.phone_no)=11);


**Elapsed: 00:00:00.79**

Execution Plan
/----------------------------------------------------------
Plan hash value: 3844306404

/----------------------------------------------------------------------------------
| Id  | Operation             | Name     | Rows  | Bytes | Cost (%CPU)| Time     |
/----------------------------------------------------------------------------------
|   0 | SELECT STATEMENT      |          |     4 |   484 |  2267  (76)| 00:00:28 |
|   1 |  UNION-ALL            |          |       |       |            |          |
|*  2 |   HASH JOIN RIGHT SEMI|          |     1 |   121 |   567   (2)| 00:00:07 |
|   3 |    VIEW               | VW_NSO_1 |   559 | 12298 |   280   (2)| 00:00:04 |
|*  4 |     TABLE ACCESS FULL | T2       |   559 |  6708 |   280   (2)| 00:00:04 |
|   5 |    TABLE ACCESS FULL  | T1       | 55915 |  5405K|   285   (2)| 00:00:04 |
|*  6 |   HASH JOIN RIGHT SEMI|          |     1 |   121 |   567   (2)| 00:00:07 |
|   7 |    VIEW               | VW_NSO_2 |   559 | 12298 |   280   (2)| 00:00:04 |
|*  8 |     TABLE ACCESS FULL | T2       |   559 |  6708 |   280   (2)| 00:00:04 |
|   9 |    TABLE ACCESS FULL  | T1       | 55915 |  5405K|   285   (2)| 00:00:04 |
|* 10 |   HASH JOIN RIGHT SEMI|          |     1 |   121 |   567   (2)| 00:00:07 |
|  11 |    VIEW               | VW_NSO_3 |   559 | 12298 |   280   (2)| 00:00:04 |
|* 12 |     TABLE ACCESS FULL | T2       |   559 |  6708 |   280   (2)| 00:00:04 |
|  13 |    TABLE ACCESS FULL  | T1       | 55915 |  5405K|   285   (2)| 00:00:04 |
|* 14 |   HASH JOIN RIGHT SEMI|          |     1 |   121 |   567   (2)| 00:00:07 |
|  15 |    VIEW               | VW_NSO_4 |   559 | 12298 |   280   (2)| 00:00:04 |
|* 16 |     TABLE ACCESS FULL | T2       |   559 |  6708 |   280   (2)| 00:00:04 |
|  17 |    TABLE ACCESS FULL  | T1       | 55915 |  5405K|   285   (2)| 00:00:04 |
/----------------------------------------------------------------------------------

Predicate Information (identified by operation id):
/---------------------------------------------------

   2 - access("PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,8))
   4 - filter(LENGTH("T2"."PHONE_NO")=8)
   6 - access("PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,9))
   8 - filter(LENGTH("T2"."PHONE_NO")=9)
  10 - access("PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,10))
  12 - filter(LENGTH("T2"."PHONE_NO")=10)
  14 - access("PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,11))
  16 - filter(LENGTH("T2"."PHONE_NO")=11)


Statistics
/----------------------------------------------------------
          0  recursive calls
          0  db block gets
       8244  consistent gets       <<--逻辑读已经降到一万以下 0="" 1="" 508="" 534="" physical="" reads="" redo="" size="" bytes="" sent="" via="" sql*net="" to="" client="" received="" from="" roundtrips="" sorts="" (memory)="" (disk)="" rows="" processed="" <="" code=""></--逻辑读已经降到一万以下></code></pre>

<p>通过采用改写为union 的方式来解决即可。可以看到，当前执行计划已经变成hash join，不再存在filter连接了。但现在对于这条SQL来说，是不是最优的呢？我们继续考虑一下，创建函数索引，是不是能更优化？</p>
<pre><code> 
create index IDX_T1_PHONE_NO8 on t1(SUBSTR(phone_no,1,8));
create index IDX_T1_PHONE_NO9 on t1(SUBSTR(phone_no,1,9));

**Elapsed: 00:00:00.52**

Execution Plan
----------------------------------------------------------
Plan hash value: 2507792230

----------------------------------------------------------------------------------------------------
| Id  | Operation                       | Name             | Rows  | Bytes | Cost (%CPU)| Time     |
----------------------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT                |                  |  2236 |   216K|  1971  (68)| 00:00:24 |
|   1 |  UNION-ALL                      |                  |       |       |            |          |
|   2 |   VIEW                          | VM_NWVW_5        |   559 | 55341 |   647   (1)| 00:00:08 |
|   3 |    HASH UNIQUE                  |                  |   559 | 74347 |   647   (1)| 00:00:08 |
|   4 |     NESTED LOOPS                |                  |   565 | 75145 |   646   (1)| 00:00:08 |
|*  5 |      INDEX FAST FULL SCAN       | IDX_T2_PHONENO   |   559 |  6708 |    51   (4)| 00:00:01 |
|   6 |      TABLE ACCESS BY INDEX ROWID| T1               |     1 |   121 |     3   (0)| 00:00:01 |
|*  7 |       INDEX RANGE SCAN          | IDX_T1_PHONE_NO8 |     1 |       |     1   (0)| 00:00:01 |
|   8 |   VIEW                          | VM_NWVW_6        |   559 | 55341 |   647   (1)| 00:00:08 |
|   9 |    HASH UNIQUE                  |                  |   559 | 74906 |   647   (1)| 00:00:08 |
|  10 |     NESTED LOOPS                |                  |   565 | 75710 |   646   (1)| 00:00:08 |
|* 11 |      INDEX FAST FULL SCAN       | IDX_T2_PHONENO   |   559 |  6708 |    51   (4)| 00:00:01 |
|  12 |      TABLE ACCESS BY INDEX ROWID| T1               |     1 |   122 |     3   (0)| 00:00:01 |
|* 13 |       INDEX RANGE SCAN          | IDX_T1_PHONE_NO9 |     1 |       |     1   (0)| 00:00:01 |
|  14 |   VIEW                          | VM_NWVW_7        |   559 | 55341 |   339   (3)| 00:00:05 |
|  15 |    HASH UNIQUE                  |                  |   559 | 77701 |   339   (3)| 00:00:05 |
|* 16 |     HASH JOIN                   |                  |   565 | 78535 |   337   (2)| 00:00:05 |
|* 17 |      INDEX FAST FULL SCAN       | IDX_T2_PHONENO   |   559 |  6708 |    51   (4)| 00:00:01 |
|  18 |      TABLE ACCESS FULL          | T1               | 55915 |  6934K|   285   (2)| 00:00:04 |
|  19 |   VIEW                          | VM_NWVW_8        |   559 | 55341 |   339   (3)| 00:00:05 |
|  20 |    HASH UNIQUE                  |                  |   559 | 77701 |   339   (3)| 00:00:05 |
|* 21 |     HASH JOIN                   |                  |   565 | 78535 |   337   (2)| 00:00:05 |
|* 22 |      INDEX FAST FULL SCAN       | IDX_T2_PHONENO   |   559 |  6708 |    51   (4)| 00:00:01 |
|  23 |      TABLE ACCESS FULL          | T1               | 55915 |  6934K|   285   (2)| 00:00:04 |
----------------------------------------------------------------------------------------------------

Predicate Information (identified by operation id):
---------------------------------------------------

   5 - filter(LENGTH("T2"."PHONE_NO")=8)
   7 - access(SUBSTR("PHONE_NO",1,8)="T2"."PHONE_NO")
  11 - filter(LENGTH("T2"."PHONE_NO")=9)
  13 - access(SUBSTR("PHONE_NO",1,9)="T2"."PHONE_NO")
  16 - access(SUBSTR("PHONE_NO",1,9)=SUBSTR("T2"."PHONE_NO",1,9) AND
              "T2"."PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,10) AND
              SUBSTR("PHONE_NO",1,8)=SUBSTR("T2"."PHONE_NO",1,8))
  17 - filter(LENGTH("T2"."PHONE_NO")=10)
  21 - access(SUBSTR("PHONE_NO",1,9)=SUBSTR("T2"."PHONE_NO",1,9) AND
              "T2"."PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,11) AND
              SUBSTR("PHONE_NO",1,8)=SUBSTR("T2"."PHONE_NO",1,8))
  22 - filter(LENGTH("T2"."PHONE_NO")=11)


Statistics
----------------------------------------------------------
          0  recursive calls
          0  db block gets
       3138  consistent gets           <<--逻辑读降到最低了 0="" 1="" 508="" 534="" physical="" reads="" redo="" size="" bytes="" sent="" via="" sql*net="" to="" client="" received="" from="" roundtrips="" sorts="" (memory)="" (disk)="" rows="" processed="" <="" code=""></--逻辑读降到最低了></code></pre>
上述的优化，对于这条SQL，应该是最优了，消耗的逻辑读最少，执行时间也只需要52ms，但因为多了两个函数索引的维护开销，如果这两张表是频繁的更新插入的话，索引的维护会有一定的影响。那我们看看不建立索引，有没有一个平衡的优化方案？

2）    其实存在多种改写方法，这里给出另一种.t2只设置到phone_no和虚拟的length(phone_no)两个字段,即行长为14个字节，千万级的表的大小为14*10，000，000字节即只有100M左右，采用with as写法，避免去创建复合索引（phone_no，length(phone_no)）走index fast full scan来避免全表扫描，避免了索引维护成本。

<pre><code> 
with a as
 (select /*+MATERIALIZE*/
   length(phone_no) as len, phone_no
    from t2)
select /*+use_hash(a,t1) leading(a t1)*/
 t1.phone_no, t1.ext, t1.v1, t1.padding
  from t1, a
 where (a.len = 8 and a.phone_no = substr(t1.phone_no, 1, 8))
    or (a.len = 9 and a.phone_no = substr(t1.phone_no, 1, 9))
    or (a.len = 10 and a.phone_no = substr(t1.phone_no, 1, 10))
    or (a.len = 11 and a.phone_no = substr(t1.phone_no, 1, 11));
</code></pre>
改写后数据库CBO优化器会自动展开or（不需要改写为union了，当然改写也可以）,展开后的执行计划如下
<pre><code> 
**Elapsed: 00:00:00.95**

Execution Plan
/----------------------------------------------------------
Plan hash value: 3776602953

/----------------------------------------------------------------------------------------------------------------
| Id  | Operation                  | Name                      | Rows  | Bytes |TempSpc| Cost (%CPU)| Time     |
/----------------------------------------------------------------------------------------------------------------
|   0 | SELECT STATEMENT           |                           |   225K|    26M|       |  3957   (2)| 00:00:48 |
|   1 |  TEMP TABLE TRANSFORMATION |                           |       |       |       |            |          |
|   2 |   LOAD AS SELECT           | SYS_TEMP_0FD9D6613_2E5CA5 |       |       |       |            |          |
|   3 |    TABLE ACCESS FULL       | T2                        | 55914 |   655K|       |   279   (1)| 00:00:04 |
|   4 |   CONCATENATION            |                           |       |       |       |            |          |
|*  5 |    HASH JOIN               |                           | 56458 |  6836K|  2024K|   710   (2)| 00:00:09 |
|*  6 |     VIEW                   |                           | 55914 |  1365K|       |    29   (7)| 00:00:01 |
|   7 |      TABLE ACCESS FULL     | SYS_TEMP_0FD9D6613_2E5CA5 | 55914 |   655K|       |    29   (7)| 00:00:01 |
|   8 |     TABLE ACCESS FULL      | T1                        | 55915 |  5405K|       |   285   (2)| 00:00:04 |
|*  9 |    HASH JOIN               |                           | 56458 |  6836K|  2024K|   710   (2)| 00:00:09 |
|* 10 |     VIEW                   |                           | 55914 |  1365K|       |    29   (7)| 00:00:01 |
|  11 |      TABLE ACCESS FULL     | SYS_TEMP_0FD9D6613_2E5CA5 | 55914 |   655K|       |    29   (7)| 00:00:01 |
|  12 |     TABLE ACCESS FULL      | T1                        | 55915 |  5405K|       |   285   (2)| 00:00:04 |
|* 13 |    HASH JOIN               |                           | 56458 |  6836K|  2024K|   710   (2)| 00:00:09 |
|* 14 |     VIEW                   |                           | 55914 |  1365K|       |    29   (7)| 00:00:01 |
|  15 |      TABLE ACCESS FULL     | SYS_TEMP_0FD9D6613_2E5CA5 | 55914 |   655K|       |    29   (7)| 00:00:01 |
|  16 |     TABLE ACCESS FULL      | T1                        | 55915 |  5405K|       |   285   (2)| 00:00:04 |
|* 17 |    HASH JOIN               |                           | 56458 |  6836K|  2024K|   710   (2)| 00:00:09 |
|* 18 |     VIEW                   |                           | 55914 |  1365K|       |    29   (7)| 00:00:01 |
|  19 |      TABLE ACCESS FULL     | SYS_TEMP_0FD9D6613_2E5CA5 | 55914 |   655K|       |    29   (7)| 00:00:01 |
|  20 |     TABLE ACCESS FULL      | T1                        | 55915 |  5405K|       |   285   (2)| 00:00:04 |
/----------------------------------------------------------------------------------------------------------------

Predicate Information (identified by operation id):
/---------------------------------------------------

   5 - access("A"."PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,11))
   6 - filter("A"."LEN"=11)
   9 - access("A"."PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,10))
       filter(LNNVL("A"."LEN"=11) OR LNNVL("A"."PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,11)))
  10 - filter("A"."LEN"=10)
  13 - access("A"."PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,9))
       filter((LNNVL("A"."LEN"=10) OR LNNVL("A"."PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,10))) AND
              (LNNVL("A"."LEN"=11) OR LNNVL("A"."PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,11))))
  14 - filter("A"."LEN"=9)
  17 - access("A"."PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,8))
       filter((LNNVL("A"."LEN"=9) OR LNNVL("A"."PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,9))) AND
              (LNNVL("A"."LEN"=10) OR LNNVL("A"."PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,10))) AND (LNNVL("A"."LEN"=11) OR
              LNNVL("A"."PHONE_NO"=SUBSTR("T1"."PHONE_NO",1,11))))
  18 - filter("A"."LEN"=8)


Statistics
/----------------------------------------------------------
          3  recursive calls
        160  db block gets
       5795  consistent gets  <<---逻辑读大幅降低 0="" 1="" 151="" 508="" 534="" 576="" physical="" reads="" redo="" size="" bytes="" sent="" via="" sql*net="" to="" client="" received="" from="" roundtrips="" sorts="" (memory)="" (disk)="" rows="" processed="" <="" code=""></---逻辑读大幅降低></code></pre>

<p>这样改写以后，逻辑读大幅降低，执行时间降到95ms左右。并且这个优化方案不需要在两张表上创建任何的索引。</p>
<p>综上所述，优化的思路都是找出产生低效执行计划filter这个关键，然后判断到出现问题的根源是因为or存在导致无法走hash join只能走filter表连接方式的问题，复杂的or条件无法做or expansion。</p>
<p>知道了原因，就是根据相应的情况去进行优化，虽然创建索引可以达到这条SQL的最佳优化效果，但是运营商的环境，业务表往往需要不断的更新插入，所以经过考虑，最后向客户推荐了第二种优化方案。</p>
<p>所以，有时不是执行时间最快，消耗资源最少的优化方案就是最适合客户环境的，还需要权衡，有时可能是次优的方案才是最适合客户的，我们要学会取舍:-)</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;运营商异常缓慢SQL优化&quot;&gt;&lt;a href=&quot;#运营商异常缓慢SQL优化&quot; class=&quot;headerlink&quot; title=&quot;运营商异常缓慢SQL优化&quot;&gt;&lt;/a&gt;运营商异常缓慢SQL优化&lt;/h1&gt;&lt;p&gt;今天到一个运营商进行深度巡检时，发现一条SQL运行次数频繁，并且占用资源非常高，这条SQL是对两个千万级的大表进行关联，根据电话号码进行查询，原来的语句运行非常缓慢，常常半个小时都执行不完，真不知道业务是怎么忍受运行这么缓慢的SQL。&lt;/p&gt;
&lt;p&gt;因为需要对客户信息进行保密，只能在自己电脑上模拟相应的数据与优化结果&lt;/p&gt;
&lt;p&gt;先创建两个表，然后模拟表的数据，分别插入3千万与2千5百万&lt;br&gt;
    
    </summary>
    
      <category term="oracle" scheme="http://username.github.io/categories/oracle/"/>
    
    
      <category term="oracle,sql tuning" scheme="http://username.github.io/tags/oracle-sql-tuning/"/>
    
  </entry>
  
  <entry>
    <title>SYSTEM表空间异常增长问题分析（二）</title>
    <link href="http://username.github.io/2016/08/10/%E7%B3%BB%E7%BB%9F%E8%A1%A8%E7%A9%BA%E9%97%B4%E5%BC%82%E5%B8%B8%E5%A2%9E%E9%95%BF%E4%BA%8C/"/>
    <id>http://username.github.io/2016/08/10/系统表空间异常增长二/</id>
    <published>2016-08-09T16:00:00.000Z</published>
    <updated>2017-02-03T08:40:52.517Z</updated>
    
    <content type="html"><![CDATA[<h1 id="继续分析"><a href="#继续分析" class="headerlink" title="继续分析"></a>继续分析</h1><p>又一个周未过去了，但是在周未的时候，系统再次报错，在system表空间已扩展到32G的情况下，逼不得已再把system表空间再扩充了64G。这样下去不是办法啊，必须要想出一个彻底解决的方案。</p>
<p>检查hisgram$这个表，发现已增长了一千多万</p>
<pre><code> 
SQL> select count(*) from histgrm$;            

  COUNT(*)            
----------            
17679019

</code></pre>

<p>检查这个表占用最多的是那些表的柱状图统计信息</p>
<pre><code> 

Table    count(*)        partitions 
F_XXXXX_DDDDDDDDDD_H    187883        1500  <<<------ 33="" 62="" 1907="" 10176="" 12073="" 12821="" 12877="" 12878="" 13190="" 14825="" 16040="" 16555="" 17268="" 17673="" 17804="" 23433="" 65124="" 77148="" f_xx_ddddd_ggggg_vvvv_h="" <<<------="" a_d_xxx_xxxx_ddu="" f_ag_loan_cont_s="" f_ag_loan_apl_msg_s="" f_ag_elec_acpt_dra_s="" f_as_guar_msg_s="" f_pt_cred_org_pt_msg_s="" f_ev_in_lend_buss_s="" f_ev_exp_bar_trad_s="" f_ev_loan_out_acc_msg_s="" f_ev_remit_fund_trad_s="" f_ev_imp_arr_ord_trad_s="" f_ev_abch_rem_fud_trad_s="" f_ev_cbill_coll_trad_s="" f_ev_online_aut_orig_s="" <="" code=""></------></code></pre>        

<p>前面三个表的记录数最多，特别是前面两个，每个表的分区数一千多个，所以每收集一次统计信息，就会增加非常多的记录，所以system 表空间消耗得特别快。</p>
<p>既然知道是因为柱状图的收集而引起的，那柱状图的作用是什么呢？当系统中的某些表存在高度不均匀的数据分布时，使用柱状图能够产生更好的选择性评估，从而产生更加优化的执行计划，如判定是选择走索引好还是走全表好。其实这对于普通的ORACLE数据库是非常好的特性，因为使用索引，能提高普通ORACLE数据库的性能，但我们现在的环境则相反，我们现在是EXADATA，在EXADATA里，通常建议是尽量减少索引，利用EXADATA的storage index特性能提高SQL的性能，使用普通的btree索引，反而性能会下降得厉害。正因为此，这些业务表上，除了主键外，都没有索引，因此，柱状图对于exadata的环境是没有什么用处的。</p>
<p>既然知道了原理，那我们就明白，histgrm$的异常增长，柱状图的收集，不会给我们的系统带来任何的好处，那我们为什么还要收集它呢？</p>
<p>检查系统当前的统计信息收集策略</p>
<pre><code> 
SQL> select client_name,status from dba_autotask_client;                 

CLIENT_NAME                                                      STATUS  
/-------------------------------------------------------------- /--------
auto optimizer stats collection                                  ENABLED 
auto space advisor                                               ENABLED 
sql tuning advisor                                               ENABLED 
</code></pre>    

<p>当前是系统默认的自动收集，即表的数据量变化达到了表的大小10%时，即会自动收集统计信息。而这个自动收集统计信息的功能，其同时也会自动收集柱状图的相关信息，正因为这样，才会导致每个周未，system表空间都异常增长，原因就是周未的时候，作了自动的统计信息收集。</p>
<pre><code> 
select dbms_stats.get_prefs('method_opt') from dual;
DBMS_STATS.GET_PREFS('METHOD_OPT')
/-------------------------------------------------------------------------------
FOR ALL COLUMNS SIZE AUTO

</code></pre>    

<p>从上面的查询中就可以看到当前自动收集是打开了柱状图的自动收集功能的。我们也可以单独查询上述最大的那三张表是不是也是打开了柱状图的自动收集功能的。</p>
<pre><code> 
SQL> select dbms_stats.get_prefs('method_opt','DWUSR','F_XXXXX_DDDDDDDDDD_H') from dual;

DBMS_STATS.GET_PREFS('METHOD_OPT','DWUSR','F_XXXXX_DDDDDDDDDD_H')
/--------------------------------------------------------------------------------
FOR ALL COLUMNS SIZE AUTO


SQL> select dbms_stats.get_prefs('method_opt','DWUSR','F_XX_DDDDD_GGGGG_VVVV_H') from dual;

DBMS_STATS.GET_PREFS('METHOD_OPT','DWUSR','F_XX_DDDDD_GGGGG_VVVV_H')
/--------------------------------------------------------------------------------
FOR ALL COLUMNS SIZE AUTO



SQL> select dbms_stats.get_prefs('method_opt','DWUSR','A_D_XXX_XXXX_DDU') from dual;

DBMS_STATS.GET_PREFS('METHOD_OPT','DWUSR','A_D_XXX_XXXX_DDU')
/--------------------------------------------------------------------------------
FOR ALL COLUMNS SIZE AUTO

</code></pre>    

<p>从上述的结果更加确信了上述的推测，现在我们要验证的是，不收集这个柱状图统计信息，这个histgrm$基表是不是就不会停止增长了。我们取三个表中最小的那个表A_D_XXX_XXXX_DDU进行试验。</p>
<pre><code> 
SQL>   exec dbms_stats.DELETE_TABLE_STATS(OWNNAME=> 'DWUSR',TABNAME=>'A_D_XXX_XXXX_DDU');   

PL/SQL procedure successfully completed.

我们先删除了这个表的统计信息

SQL> select count(*) from histgrm$ a where a.obj# in (select b.object_id from dba_objects b where b.object_name='A_D_XXX_XXXX_DDU');

  COUNT(*)
/----------
         0
删除后，在histgrm$里就没有这个表的相关信息了，histgrm$的空间就可以被重用了。但因为是数据字典表，这个空出来的空间不能被回收，只能被另外的记录重用。

</code></pre>


<p>我们重新以不收集柱状图的方式重新收集这个表的信息，指定</p>
<p>METHOD_OPT=&gt;’for all columns size 1’</p>
<pre><code> 
15:20:53 SQL> exec dbms_stats.GATHER_TABLE_STATS(OWNNAME=> 'DWUSR',TABNAME=>'A_D_XXX_XXXX_DDU',ESTIMATE_PERCENT=>dbms_stats.auto_sample_size,METHOD_OPT=>'for all columns size 1') ;

PL/SQL procedure successfully completed.

Elapsed: 00:34:35.72

15:55:31 SQL>                   select count(*) from histgrm$ a where a.obj# in (select b.object_id from dba_objects b where b.object_name='A_D_XXX_XXXX_DDU');

  COUNT(*)
----------
         0

Elapsed: 00:00:00.03    

</code></pre>

<p>收集完成后，我们检查histgrm$，果然如我们所期望的一样，没有任何的记录，即在不收集柱状图的情况下，这个histgrm$基表是不会增长的。</p>
<p>OK，那我们验证成功了，既然这个柱状图对exadata 环境没什么用，那我们就把全库的柱状图都禁止好了，进行以下的设置</p>
<pre><code> 
16:14:22 SQL>      exec dbms_stats.set_param(pname=>'METHOD_OPT',pval=>'FOR ALL COLUMNS SIZE 1');

PL/SQL procedure successfully completed.

Elapsed: 00:00:00.04
16:19:57 SQL> select dbms_stats.get_prefs('method_opt') from dual;

DBMS_STATS.GET_PREFS('METHOD_OPT')
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
FOR ALL COLUMNS SIZE 1

全库的统计信息收集属性改变了，不收集柱状图的信息

Elapsed: 00:00:00.00
16:20:11 SQL> select dbms_stats.get_prefs('method_opt','DWUSR','F_XXXXX_DDDDDDDDDD_H') from dual;

DBMS_STATS.GET_PREFS('METHOD_OPT','DWUSR','F_XXXXX_DDDDDDDDDD_H')
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
FOR ALL COLUMNS SIZE 1

Elapsed: 00:00:00.00
16:20:25 SQL> 
对应的表的收集属性也跟着变化了
</code></pre>

<p>至此问题得到完美的解决，SYSTEM表空间再不会因为histgrm$这个表的异常增长而撑爆。但是，如果在非EXADATA的环境，并且表字段的数据分布不均的情况下，柱状图还是非常有用的，这样 histgrm$增长就在所难免了。解决问题，只要知道了其原理，具体问题具体分析，一般都能找到解决方案。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;继续分析&quot;&gt;&lt;a href=&quot;#继续分析&quot; class=&quot;headerlink&quot; title=&quot;继续分析&quot;&gt;&lt;/a&gt;继续分析&lt;/h1&gt;&lt;p&gt;又一个周未过去了，但是在周未的时候，系统再次报错，在system表空间已扩展到32G的情况下，逼不得已再把system表空间
    
    </summary>
    
      <category term="oracle" scheme="http://username.github.io/categories/oracle/"/>
    
    
      <category term="oracle,11.2.0.4" scheme="http://username.github.io/tags/oracle-11-2-0-4/"/>
    
  </entry>
  
  <entry>
    <title>系统参数设置不当导致ORACLE坏块的故事</title>
    <link href="http://username.github.io/2016/08/02/%E7%B3%BB%E7%BB%9F%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE%E4%B8%8D%E5%BD%93%E5%AF%BC%E8%87%B4ORACLE%E5%9D%8F%E5%9D%97%E7%9A%84%E6%95%85%E4%BA%8B/"/>
    <id>http://username.github.io/2016/08/02/系统参数设置不当导致ORACLE坏块的故事/</id>
    <published>2016-08-01T16:00:00.000Z</published>
    <updated>2017-02-03T08:44:49.324Z</updated>
    
    <content type="html"><![CDATA[<h2 id="个人介绍"><a href="#个人介绍" class="headerlink" title="个人介绍"></a>个人介绍</h2><p>本人TY，从事ORACLE DBA十五年，从ORACLE 8I开始，一直奋战在一线，本着对技术的狂热，一直走到今天，积累了大量的经验与案例，期待静下心来，将这些案例与经验化成文字，与大家分享，共同进步。</p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>作为从事DBA多年的TY来说，与奋战在一线的同行们一样，每天都会遇到各种各样的奇怪问题，这些问题有些莫名奇妙的自动出现，然后莫名奇妙的自动消失，但这世上不会有无缘无故的爱，也不会有无缘无故的恨：-），TY是一个喜欢创根问根的人，非常喜欢接受数据库奇怪问题的挑战。也可以简称“自虐”。</p>
<p>最近两天，有个客户打电话给TY，说他的数据库刚从AIX迁移到PC 服务器上，使用的是OLE 6的操作系统，最近备份时，出现报错，系统中居然报归档文件存在坏块。</p>
<p>这个就非常奇怪了，数据库出现坏块就常见，归档文件出现坏块这个极为罕见，这挑起了TY的好奇心，决定到客户现场一探究竟。</p>
<p><code>这里讲述的是一个，对于未知问题，无从下手的情况下，如何分析解决问题的过程。</code></p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a><strong>背景</strong></h2><p><strong>客户的数据库是11.2.0.1，刚从AIX上迁移到PC服务器上，迁移时，归档文件是放到FRADG上的，备份一直没有问题，但最近将归档目录修改到文件系统后，备份时alter.log就出现如下的报错：</strong></p>
   <pre><code>RMAN>backup archivelog all;

  Starting backup at 06-Jan-16
  current log archived
  allocated channel: ORA_DISK_1
  channel ORA_DISK_1: SID=148 device type=DISK
  channel ORA_DISK_1: starting archived log backup set
  channel ORA_DISK_1: specifying archived log(s) in backup set
  input archived log thread=1 sequence=4 RECID=1 STAMP=793260539
  input archived log thread=1 sequence=5 RECID=2 STAMP=793260573
  input archived log thread=1 sequence=6 RECID=3 STAMP=793260647
  input archived log thread=1 sequence=7 RECID=4 STAMP=793260764
  input archived log thread=1 sequence=8 RECID=5 STAMP=793260835
  input archived log thread=1 sequence=9 RECID=6 STAMP=793260868A6
  channel ORA_DISK_1: starting piece 1 at 06-Jan-16
  RMAN-571: ===========================================================
  RMAN-569: =============== ERROR MESSAGE STACK FOLLOWS ===============
  RMAN-571: ===========================================================
  RMAN-3009: failure of backup command on ORA_DISK_1 channel at 01/06/2016
  06:21:59
  ORA-19599: block number 2048 is corrupt in archived log
  /u01/app/oracle/flash_recovery_area/ORCL/archivelog/2016_01_06/o1_mf_1_10_84j
  xxb4d_.arc</code></pre>





  <pre><code>[oracle@localhost trace]$ tail -f alert_orcl.log

Bad header found during backing up archived log
  Data in bad block - seq:0. bno:0. time:0
  beg:0 cks:0
  calculated check value: 0
  Reread of seq=10, blocknum=2048,
  file=/u01/app/oracle/flash_recovery_area/ORCL/archivelog/2016_01_06/o1_mf_1_1
  0_84jxxb4d_.arc, found same corrupt data
  Reread of seq=10, blocknum=2048,
  file=/u01/app/oracle/flash_recovery_area/ORCL/archivelog/2016_01_06/o1_mf_1_1
  0_84jxxb4d_.arc, found same corrupt data
  Reread of seq=10, blocknum=2048,
  file=/u01/app/oracle/flash_recovery_area/ORCL/archivelog/2016_01_06/o1_mf_1_1
  0_84jxxb4d_.arc, found same corrupt data
  Reread of seq=10, blocknum=2048,
  file=/u01/app/oracle/flash_recovery_area/ORCL/archivelog/2016_01_06/o1_mf_1_1
  0_84jxxb4d_.arc, found same corrupt data
  Reread of seq=10, blocknum=2048,
  file=/u01/app/oracle/flash_recovery_area/ORCL/archivelog/2016_01_06/o1_mf_1_1
  0_84jxxb4d_.arc, found same corrupt data
  Deleted Oracle managed file
  /u01/app/oracle/flash_recovery_area/ORCL/backupset/2016_01_06/o1-mf_annnn_TAG20160106T062152_84jyb44j_.bkp</code></pre>


<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>对于corrupt data，一般都是发生在数据库文件中，有两种情况，一种是物理损坏，是指数据库不能读取到该块内部的数据结构，一般是因为硬件出现问题，内存问题、OS问题、IO子系统问题等引起。而逻辑损坏，则大多是指数据库能读取到该块的数据结构，但是因为数据结构的值不一致，从而被数据库标识为坏块，大部分的逻辑损坏，很多都是因为ORACLE 的BUG 造成的。</p>
<p>但对于客户现在这种情况，是归档文件损坏。而用户的环境是新的机器，存储也是新的。硬件出现问题的概率较低，对于内存，OS，IO等问题，如果存在，肯定数据库本身的数据文件也会报坏块，而现在只是归档文件有问题，所以基本上可以排除物理坏块的的可能。</p>
<p>对于归档文件出现坏块这种情况，在TY十多年的DBA生涯中也极少遇到，正在苦思冥想，不知如何下手的时候，突然灵光一闪，客户曾提到过，当刚迁移完的时候，归档是存放在ASM中的，那个时候没有出现这种情况。只有迁移到文件系统后，才出现这种情况，这是一条多么重要的线索啊。</p>
<p>认真思考了一下归档文件涉及到的进程，无非就是arch写，然后备份时RMAN读的时候报错。那是不是写的时候出现了问题呢？</p>
<p>为了证实自己的想法，决定对归档进程进行trace，看看归档进程在进行归档时，ASM与文件系统之间有没有什么特别的地方。</p>
<pre><code>
会话一：
# ps -ef|grep arc
oracle    2768     1  0 22:11 ?        00:00:01 ora_arc0_orcl
root      3000  2395  0 23:09 pts/1    00:00:00 grep arc

strace –o /tmp/strace.log –p 2768

会话二：
sqlplus / as sysdba
alter syste switch logfile;
</code></pre>

<p>这个时候，会产生归档进程的整个归档trace，仔细检查这个trace，发现写文件时，只有以下的相关信息：</p>
<pre><code>
open("...../1_21_900928246.dbf", O_RDWR|O_SYNC|O_DIRECT) = 21
open("...../1_21_900928246.dbf", O_RDWR|O_SYNC|O_DIRECT) = 21
open("...../1_21_900928246.dbf", O_RDWR|O_SYNC|O_DIRECT) = 21
open("...../1_21_900928246.dbf", O_RDWR|O_SYNC|O_DIRECT) = 21
</code></pre>

<p>然后，将归档路径重新设置回ASM里面，重做上述的过程，对比一下strace的输出</p>
<pre><code>
open("/dev/raw/raw7", O_RDWR|O_NONBLOCK|O_SYNC|O_DIRECT) = 20
open("/dev/raw/raw6", O_RDWR|O_NONBLOCK|O_SYNC|O_DIRECT) = 20
open("/proc/6236/stat", O_RDONLY)       = 20
</code></pre>

<p>发现其多了一个O_NONBLOCK的关键字，对于一个IO操作的句柄会遇到阻塞IO 和非阻塞IO 的概念, 这里对于这两种socket 先做一下说明：<br>基本概念：<br>  阻塞IO::<br>   socket 的阻塞模式意味着必须要做完IO 操作（包括错误）才会返回。非阻塞IO::<br>   非阻塞模式下无论操作是否完成都会立刻返回，需要通过其他方式来判断具体操作是否成功。</p>
<p>存在O_NONBLOCK的关键字，即其是非阻塞的IO操作，这从ASM的原理上可以推测到，因为ASM是直接操作底层磁盘的，其没有文件缓存，那问题会不会出在O_SYNC|O_DIRECT这两个参数上，难道是写归档日志的方式不对，导致了归档出现坏块？</p>
<p>马上到metelink上输入O_SYNC O_DIRECT进行搜索，发现排在BUG的第一位就有一个相类似的BUG，其描述是在linux上使用EXT4的文件系统存放archived log ,redo log ,datafile 文件时，数据库的参数filesystemio_options=setall时，就会出现数据库坏块。</p>
<p><img src="file:///C:\Users\Tony\Pictures\1.jpg" alt="image"></p>
<p>柳暗花明又一村，看到这个BUG，心中一阵狂喜，客户是不是命中这个BUG呢？是不是离解决问题不远了。马上登录到系统中一看归档目录，发现果然是以ext4来加载的。</p>
<p>再到数据库里查看</p>
<pre><code>
SQL> show parameter filesystem

NAME                    TYPE        VALUE
----------------------  ----------- --------
filesystemio_options    string      SETALL
</code></pre>

<p>果然与这个BUG相匹配，那么这个filesystemio_options是什么参数呢？ORACLE数据库里面有两个参数控制IO的行为，也就是说，我们可以通过filesystemio_options与disk_asynch_io这两个参数来优化ORACLE数据库的IO性能。</p>
<p>filesystemio_options 这个参数是允许数据库对IO进行间接或直接，同步或异步读写，这个参数默认是none，这意味着，数据库对文件系统IO操作模式是同步读写，对文件系统的cache是间接读写。Oracle推荐这个参数是使用setall，这个参数值是执行IO操作时绕过了文件系统的cache，直接读写到磁盘上。</p>
<p>而disk_asynch_io这个参数是默认为true的，即启用异步IO。</p>
<p>基于上述的原理，所以当filesystemio_options设置为setall时，我们看到O_SYNC|O_DIRECT的关键字，其绕过了EXT4上的文件系统缓存，直接对IO进行操作，导致触发了14594193这个BUG。</p>
<h2 id="原因总结及建议"><a href="#原因总结及建议" class="headerlink" title="原因总结及建议"></a>原因总结及建议</h2><p>通过对上述的分析，可以知道是因为客户将归档文件存放到了EXT4上的文件系统，而数据库的参数filesystemio_options设置为setall时，数据库在做IO操作时，绕过了EXT4文件系统的缓存，从而触发了BUG而引起了坏块，所以这种坏块属于逻辑坏块。</p>
<p>这个问题在metalink的文档ORA-1578 ORA-353 ORA-19599 Corrupt blocks with zeros when filesystemio_options=SETALL on ext4 file system using Linux (文档 ID 1487957.1)里有详细的描述，在这里我就不帖出来了，各位自已去查阅吧。</p>
<p>这个文档提及，从10.1.0.2 to 12.1.0.1都存在这个BUG，也就是说，从10.2.0.2引入filesystemio_options这个参数，只要设为SETALL，结合EXT4，就会有可能遇到这个BUG。</p>
<h2 id="建议："><a href="#建议：" class="headerlink" title="建议："></a><strong>建议：</strong></h2><p>万事知道原理后，解决就非常容易了，要不修改filesystemio_options这个参数为非SETALL值。</p>
<pre><code>
Workaround:
The workaround to avoid corruptions in the Oracle database files is to set filesystemio_options=NONE or filesystemio_options=DIRECTIO or filesystemio_options=ASYNCH in the database parameter file (spfile / init<sid>.ora).
</sid></code></pre>

<p>要不就不要使用EXT4来存放数据库的相关文件，改为其他文件系统格式或直接存放到ASM上。</p>
<p>终于解决问题，可以回家了：-）</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;个人介绍&quot;&gt;&lt;a href=&quot;#个人介绍&quot; class=&quot;headerlink&quot; title=&quot;个人介绍&quot;&gt;&lt;/a&gt;个人介绍&lt;/h2&gt;&lt;p&gt;本人TY，从事ORACLE DBA十五年，从ORACLE 8I开始，一直奋战在一线，本着对技术的狂热，一直走到今天，积累了大
    
    </summary>
    
      <category term="Pelican" scheme="http://username.github.io/categories/Pelican/"/>
    
    
      <category term="Python, Pelican, GitHub, Markdown" scheme="http://username.github.io/tags/Python-Pelican-GitHub-Markdown/"/>
    
  </entry>
  
  <entry>
    <title>SYSTEM表空间异常增长问题分析（一）</title>
    <link href="http://username.github.io/2016/08/02/%E7%B3%BB%E7%BB%9F%E8%A1%A8%E7%A9%BA%E9%97%B4%E5%BC%82%E5%B8%B8%E5%A2%9E%E9%95%BF%E4%B8%80/"/>
    <id>http://username.github.io/2016/08/02/系统表空间异常增长一/</id>
    <published>2016-08-01T16:00:00.000Z</published>
    <updated>2017-02-03T08:40:01.543Z</updated>
    
    <content type="html"><![CDATA[<h2 id="个人介绍"><a href="#个人介绍" class="headerlink" title="个人介绍"></a>个人介绍</h2><p>本人TY，从事ORACLE DBA十五年，从ORACLE 8I开始，一直奋战在一线，本着对技术的狂热，一直走到今天，积累了大量的经验与案例，期待静下心来，将这些案例与经验化成文字，与大家分享，共同进步。</p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在7月30日，某客户的exadata出现aud$无法扩充system表空间的错误，检查发现，当前system表空间只有4G大小，经现场维护人员将system表空间resize到20G后，问题暂时得到解决。</p>
<p>但是在8月3日现场支持检查发现，当前的SYSTEM表空间已经增长到16G，对于三四天增长这么快，需要找出原因。</p>
<h2 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h2><p>在7月30日时，一直以为是aud$占的空间较大，导致了空间爆满，但现场检查时，却发现与我们想像的不致。</p>
<p>检查当前system表空间占用最多的对象</p>
<pre><code> SQL> select * from (select owner,segment_name,bytes/1024/1024 "size M" from dba_segments where tablespace_name='SYSTEM' order by 3 desc) where rownum <10; 50="" 52="" 53="" 54="" 240="" 312="" 672="" 14301="" owner="" segment_name="" size="" m="" ------------------------------="" ---------------------------------------------------------------------------------="" ----------="" sys="" c_obj#_intcol#="" hist_head$="" i_h_obj#_col#="" i_hh_obj#_col#="" i_hh_obj#_intcol#="" tabpart$="" sys_lob0000001100c00003$$="" c_file#_block#="" i_obj5="">
</10;></code></pre>


<p>发现占用最大的对象是C_OBJ#_INTCOL#，这个对象已经占了近14G，而aud$却排不上前十，看来经验误人，这个C_OBJ#_INTCOL#是什么对象呢？这个是一个 cluster对象。</p>
<p>簇表(cluster) 是一种可以选的存储数据方式。簇表由1组拥有相同的列而且经常被一起使用的数据表构成，这组表在存储时会共享一部分Data Blocks, 例如，employees 和 departments表都包含department_id 这个列。 当用户将这两个表组合成1个簇表时，Oracle在物理上将employees 和 departments 两张表各行的department_id 字段存储在1个Data block里。</p>
<p>cluster table在ORACLE的系统表上使用得较多，我们查一下这个cluster涉及的是那一个对象，可以通过dba_tables查到</p>
<pre><code>  
SQL> select owner,table_name,cluster_name from dba_tables where table_name='HISTGRM$';

OWNER                          TABLE_NAME                     CLUSTER_NAME
------------------------------ ------------------------------ ------------------------------
SYS                            HISTGRM$                       C_OBJ#_INTCOL#


SQL>  select owner,table_name,BLOCKS*32/1024,tablespace_name  from dba_tables where table_name='HISTGRM$';

OWNER                          TABLE_NAME                     BLOCKS*32/1024 TABLESPACE_NAME
------------------------------ ------------------------------ -------------- ------------------------------
SYS                            HISTGRM$                             13817.75 SYSTEM
</code></pre>


<p>可以看到这个cluster是HISTGRM$所用，并且这个cluster的大小就是这个HISTGRM$表的大小。为什么是这个表占据了system最多的空间呢？我们进一步研究，</p>
<p>histgrm$这个表存储的是column statistics (histograms)，即列的柱状图信息，并且从11.2.0.4开始，这个列的统计表有了一些细微的变化，增加了default value这个列，即以前不会收集柱状图的列，增加了这个列后，也会强制收集这个列的信息。</p>
<p>根据Mos的Cluster C_OBJ#_INTCOL# Growing Too Fast (Doc ID 403824.1)描述，这个基表的记录，会随着你的子分区数量的增长而呈几何级的增长。如你有55000个子分区，每个子分区有100列，每个列有200个柱状图的bucket，那么histgrm$在每次统计信息收集时， 就会增长<br>55000<em>100</em>200 = approx 1 billion rows</p>
<p>这是一个非常大的数据，当然，你的子分区不会有100列那么多，也可能不会有55000个分区，但上述的公式展示了，随着子分区的增长，每收集一次统计信息，HISTGRM$基表的的数据量会急剧增加。</p>
<p>我们检查一下当前系统中存有的子分区数量</p>
<pre><code> 
SQL> select count(*) from histgrm$;

  COUNT(*)
----------
   8417868

当前这个基表已经有8百多万行了
SQL>  select count(*) from dba_tab_subpartitions;

  COUNT(*)
----------
    113565

</code></pre>


<p>那就奇怪了，为什么一个周未过去，这个基表就急剧增长呢？以前没有这样的事呢？经查，原来系统的自动统计信息收集并没有开启，即系统不会在每天凌晨进行统计信息收集，所以system表空间一直在4G以内而没有任何的问题。</p>
<p>但为什么周未会出现system表空间不足呢？那是因为开发人员在进行完表迁移后，为了确保跑批能顺利完成，所以手工执行了统计信息的收集，所以导致了HISTGRM$基表数据的急剧增长，从而快速占据了system表空间，而aud$也是一个只要有新的连接或操作时，就会插入新的数据的，当system空间被HISTGRM$基表占据时，aud$也没有空间插入数据，所以报错。</p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>从上述的分析可以看到，当前系统存在两个问题，统计信息的收集没有开启，所以系统中表的统计信息不准确，将会导致执行计划不准，对跑批有较大影响。但是一旦开启统计信息的自动收集，那么，系统中存在着11万个子分区，将会导致HISTGRM$急剧增长。而且这个表增长后，无法通过删除数据进行收缩。</p>
<p>通过综合考虑，建议对关键的业务表进行手工的统计信息收集，并且扩充system表空间到较大的空间，并且加强对此表空间的监控，避免空间不足。这样可以保证主要的业务表涉及的SQL执行计划是准确的，另外，减少了自动收集统计信息自动收集的分区数量，使HISTGRM$能可控增长。</p>
<blockquote>
<p>Cluster C_OBJ#_INTCOL# Growing Too Fast (Doc ID 403824.1)    To BottomTo Bottom    </p>
<p>In this Document<br>Symptoms<br>Cause<br>Solution<br>APPLIES TO:</p>
<p>Oracle Database - Enterprise Edition - Version 10.2.0.2 to 11.2.0.4 [Release 10.2 to 11.2]<br>Information in this document applies to any platform.<br><strong><em> Checked for relevance on 6-Oct-2014 </em></strong><br><strong><em> Checked for relevance on 8-Mar-2016 </em></strong></p>
<p>SYMPTOMS</p>
<p>Cluster C_OBJ#_INTCOL# is growing too fast.<br>CAUSE</p>
<p>The default stats job (GATHER_STATS_JOB) or any other job based on the DBMS_STATS used to collect Database statistics is being run frequently, while having a large number of subpartitions within the database.<br>To explain how the large number of subpartitions plays a role in the problem, consider the following example:</p>
<p>If 55000 subpartitions are being used, all of which have data and if each subpartition has 100 columns and further if the histogram has 200 buckets, then the worst case scenario for number of rows in the histgrm$ table for these objects is:</p>
<p>55000<em>100</em>200 = approx 1 billion rows</p>
<p>That’s the worst case scenario since there may not be 100 columns and all subpartitions may not have data and all columns may not have 200 buckets. But it illustrates the point that histograms can take up a lot of space as new objects are created and new data is loaded.</p>
<p>To make sure of the previous information, perform the following SQL queries:</p>
<ol>
<li><p>SQL&gt; SELECT STATE FROM DBA_SCHEDULER_JOBS WHERE JOB_NAME = ‘GATHER_STATS_JOB’;</p>
<p>If the result is “scheduled”, then the default stats job is automatically running.</p>
</li>
<li><p>SQL&gt; select job_name, schedule_name, last_start_date,repeat_interval,next_run_date from dba_scheduler_jobs;</p>
<p>SQL&gt; select * from dba_scheduler_wingroup_members;</p>
<p>SQL&gt; select * from dba_scheduler_window_details;</p>
<p>This is to check for any other job that gathers statistics and determine its scheduled run time and that of the default stats job.</p>
</li>
<li><p>SQL&gt; select count(*) from histgrm$;</p>
<p>Before and after running the job, if the histgrm$ number of rows increases obviously, then the assumptions are correct.</p>
</li>
<li><p>Check the number of subpartitions in the database if it has been increased or not.</p>
</li>
</ol>
<p>SOLUTION</p>
<p>To workaround this issue:</p>
<ol>
<li><p>Adjust the scheduler of the jobs so as not to run so often or run them manually.</p>
</li>
<li><p>Avoid adding so many subpartitions to the database.</p>
</li>
</ol>
<p>Other than recreating the database, there is no other supported way to reduce the size of the cluster.</p>
</blockquote>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;个人介绍&quot;&gt;&lt;a href=&quot;#个人介绍&quot; class=&quot;headerlink&quot; title=&quot;个人介绍&quot;&gt;&lt;/a&gt;个人介绍&lt;/h2&gt;&lt;p&gt;本人TY，从事ORACLE DBA十五年，从ORACLE 8I开始，一直奋战在一线，本着对技术的狂热，一直走到今天，积累了大
    
    </summary>
    
      <category term="oracle" scheme="http://username.github.io/categories/oracle/"/>
    
    
      <category term="oracle,11.2.0.4" scheme="http://username.github.io/tags/oracle-11-2-0-4/"/>
    
  </entry>
  
</feed>
